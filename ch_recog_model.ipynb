{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packs loaded\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import imread\n",
    "import json\n",
    "import gzip\n",
    "import tarfile\n",
    "import random\n",
    "%matplotlib inline\n",
    "plt.rcParams['image.cmap'] = 'Greys'\n",
    "\n",
    "print(\"packs loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en index loaded\n",
      "tar opened\n",
      " 0% complete (1 / 79200)\n",
      "13% complete (10001 / 79200)\n",
      "25% complete (20001 / 79200)\n",
      "38% complete (30001 / 79200)\n",
      "51% complete (40001 / 79200)\n",
      "63% complete (50001 / 79200)\n",
      "76% complete (60001 / 79200)\n",
      "88% complete (70001 / 79200)\n",
      "en image loaded\n"
     ]
    }
   ],
   "source": [
    "index_data_en = []\n",
    "\n",
    "with gzip.open('data/en/index.json.gz', 'rt') as arc:\n",
    "    index_data_en.extend(json.load(arc))\n",
    "    print(\"en index loaded\")\n",
    "    \n",
    "with tarfile.open('data/en/data.tar.gz', \"r|*\") as tar:\n",
    "    print(\"tar opened\")\n",
    "    img_data_en = []\n",
    "    for i, member in enumerate(index_data_en):\n",
    "        if i%10000 == 1:\n",
    "            print(\"%2.0f%% complete (%d / %d)\" % (i / len(index_data_en) * 100, i, len(index_data_en)))\n",
    "        ti = tar.next()\n",
    "        if ti.name != member['path']:\n",
    "            print(\"ERROR: order doesn't match\")\n",
    "            break;\n",
    "        f = tar.extractfile(ti)\n",
    "        img_data_en.append(1 - (imread(f)/255))\n",
    "    img_en = np.array(img_data_en)\n",
    "    del img_data_en\n",
    "    print(\"en image loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en label loaded\n"
     ]
    }
   ],
   "source": [
    "en_chset = []\n",
    "en_chset.extend([\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"])\n",
    "en_chset.extend([\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\",\\\n",
    "              \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\"])\n",
    "en_chset.extend([\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\",\\\n",
    "              \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\"])\n",
    "en_chset.extend([\"(\", \")\", \"'\", \"\\\"\", \".\", \",\", \":\", \";\", \"!\", \"?\", \"/\", \"@\", \"#\", \"$\",\\\n",
    "              \"%\", \"^\", \"&\", \"*\", \"[\", \"]\", \"{\", \"}\", \"<\", \">\", \"~\", \"-\"])\n",
    "\n",
    "label_en = np.zeros([img_en.shape[0], len(en_chset)])\n",
    "for i, member in enumerate(index_data_en):\n",
    "    label_en[i][en_chset.index(member['target'])] = 1\n",
    "    \n",
    "print(\"en label loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffled\n"
     ]
    }
   ],
   "source": [
    "def getIndex(l, indexes):\n",
    "    return [l[i] for i in indexes]\n",
    "\n",
    "def shuffle(n, *lists):\n",
    "    perm = np.random.permutation(n)\n",
    "    lists = list(lists)\n",
    "    for i in range(len(lists)):\n",
    "        if hasattr(lists[i], \"shape\"):\n",
    "            lists[i] = lists[i][perm]\n",
    "        else:\n",
    "            lists[i] = getIndex(lists[i], perm)\n",
    "    return tuple(lists)\n",
    "\n",
    "img_en, label_en, index_data_en = shuffle(img_en.shape[0], img_en, label_en, index_data_en)\n",
    "\n",
    "print(\"shuffled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79200, 32, 32)\n",
      "{'font': 'Dotum', 'path': '0043032.png', 'weight': 'NORMAL', 'target': 'L'}\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD9CAYAAACcAsr/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f85a595c860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(img_en.shape)\n",
    "plt.figure()\n",
    "plt.imshow(img_en[0], interpolation='none')\n",
    "print(index_data_en[0])\n",
    "print(label_en[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function loaded\n"
     ]
    }
   ],
   "source": [
    "trainimg = img_en[:-5000]\n",
    "trainlabel = label_en[:-5000]\n",
    "testimg = img_en[-5000:]\n",
    "testlabel = label_en[-5000:]\n",
    "randidx = np.random.randint(trainimg.shape[0], size=2)\n",
    "\n",
    "def get_batch(i, batch_size, input_var):\n",
    "    if batch_size > input_var.shape[0]:\n",
    "        return input_var\n",
    "    start = (i*batch_size)%input_var.shape[0]\n",
    "    overflow = start + batch_size - input_var.shape[0]\n",
    "    if overflow <= 0:\n",
    "        return input_var[start:start+batch_size]\n",
    "    else:\n",
    "        return np.r_[input_var[start:], input_var[:overflow]]\n",
    "    \n",
    "def build_cnn(cnn_shape, patch_shape, X):\n",
    "    n_before = int(X.get_shape()[3])\n",
    "    layer = X\n",
    "    for idx, val in enumerate(cnn_shape):\n",
    "        W = tf.Variable(tf.truncated_normal([patch_shape[0], patch_shape[1], n_before, val], stddev=0.1))\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[val]))\n",
    "        layer = tf.nn.relu(tf.nn.conv2d(layer, W, strides=[1, 1, 1, 1], padding='SAME') + b)\n",
    "        layer = tf.nn.max_pool(layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        n_before = val\n",
    "    layer_shape = layer.get_shape().as_list()\n",
    "    n_out = layer_shape[1] * layer_shape[2] * layer_shape[3]\n",
    "    return tf.reshape(layer, [-1, n_out])\n",
    "    \n",
    "def build_nn(shape, X, Y):\n",
    "    n_before = int(X.get_shape()[1])\n",
    "    n_out = int(Y.get_shape()[1])\n",
    "    layer = X\n",
    "    for idx, val in enumerate(shape):\n",
    "        W = tf.Variable(tf.truncated_normal([n_before, val], stddev=0.1))\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[val]))\n",
    "        layer = tf.nn.relu(tf.matmul(layer, W)+b)\n",
    "        n_before = val\n",
    "    W = tf.Variable(tf.truncated_normal([n_before, n_out], stddev=0.1))\n",
    "    b = tf.Variable(tf.constant(0.1, shape=[n_out]))\n",
    "    return tf.matmul(layer, W)+b\n",
    "\n",
    "print(\"function loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 32, 32])\n",
    "Y = tf.placeholder(tf.float32, [None, 88])\n",
    "\n",
    "cnn_layer = build_cnn([16, 32], [5,5], tf.reshape(X, [-1, 32, 32, 1]))\n",
    "dense_layer = build_nn([512], cnn_layer, Y)\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "dropout = tf.nn.dropout(dense_layer, keep_prob)\n",
    "hypothesis = tf.nn.softmax(dropout)\n",
    "\n",
    "learning_rate = tf.placeholder(tf.float32)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), reduction_indices=[1]))\n",
    "\n",
    "train = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 74200, mini-batch 30 * 2473\n",
      "     0th epoch : test accuracy = 0.920\n",
      "     0th epoch : test accuracy = 0.855\n",
      "     0th epoch : test accuracy = 0.896\n",
      "     0th epoch : test accuracy = 0.906\n",
      "     0th epoch : test accuracy = 0.907\n",
      "     0th epoch : test accuracy = 0.917\n",
      "     0th epoch : test accuracy = 0.926\n",
      "     0th epoch : test accuracy = 0.929\n",
      "     0th epoch : test accuracy = 0.938\n",
      "     0th epoch : test accuracy = 0.938\n",
      "     0th epoch : test accuracy = 0.944\n",
      "     0th epoch : test accuracy = 0.946\n",
      "     0th epoch : test accuracy = 0.952\n",
      "     0th epoch : test accuracy = 0.954\n",
      "     0th epoch : test accuracy = 0.949\n",
      "     0th epoch : test accuracy = 0.952\n",
      "     0th epoch : test accuracy = 0.956\n",
      "     0th epoch : test accuracy = 0.954\n",
      "     0th epoch : test accuracy = 0.955\n",
      "     0th epoch : test accuracy = 0.958\n",
      "     0th epoch : test accuracy = 0.962\n",
      "     0th epoch : test accuracy = 0.961\n",
      "     0th epoch : test accuracy = 0.964\n",
      "     0th epoch : test accuracy = 0.964\n",
      "     0th epoch : test accuracy = 0.961\n",
      "     1th epoch : test accuracy = 0.965\n",
      "     1th epoch : test accuracy = 0.965\n",
      "     1th epoch : test accuracy = 0.964\n",
      "     1th epoch : test accuracy = 0.966\n",
      "     1th epoch : test accuracy = 0.966\n",
      "     1th epoch : test accuracy = 0.964\n",
      "     1th epoch : test accuracy = 0.966\n",
      "     1th epoch : test accuracy = 0.966\n",
      "     1th epoch : test accuracy = 0.963\n",
      "     1th epoch : test accuracy = 0.967\n",
      "     1th epoch : test accuracy = 0.967\n",
      "     1th epoch : test accuracy = 0.967\n",
      "     1th epoch : test accuracy = 0.967\n",
      "     1th epoch : test accuracy = 0.968\n",
      "     1th epoch : test accuracy = 0.967\n",
      "     1th epoch : test accuracy = 0.967\n",
      "     1th epoch : test accuracy = 0.968\n",
      "     1th epoch : test accuracy = 0.966\n",
      "     1th epoch : test accuracy = 0.968\n",
      "     1th epoch : test accuracy = 0.967\n",
      "     1th epoch : test accuracy = 0.966\n",
      "     1th epoch : test accuracy = 0.966\n",
      "     1th epoch : test accuracy = 0.967\n",
      "     1th epoch : test accuracy = 0.966\n",
      "     1th epoch : test accuracy = 0.968\n",
      "train complete : test accuracy = 0.967\n",
      "                 train accuracy = 0.979\n"
     ]
    }
   ],
   "source": [
    "#sess = tf.Session()\n",
    "#sess.run(tf.initialize_all_variables())\n",
    "\n",
    "trainsize = trainimg.shape[0]\n",
    "batchsize = 30\n",
    "batch_per_epoch = int(trainsize/batchsize)\n",
    "print (\"Training %d, mini-batch %d * %d\" % (trainsize, batchsize, batch_per_epoch))\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(Y,1), tf.argmax(hypothesis,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "lr = 0.0003\n",
    "for i in range(batch_per_epoch*2):\n",
    "    if i % 100 == 0 :\n",
    "        print (\"%6dth epoch : test accuracy = %.3f\" % \\\n",
    "               (i / batch_per_epoch, sess.run(accuracy, feed_dict={X:testimg, Y:testlabel, keep_prob:1})))\n",
    "        \n",
    "    batch_x = get_batch(i, batchsize, trainimg)\n",
    "    batch_y = get_batch(i, batchsize, trainlabel)\n",
    "    sess.run(train, feed_dict={X:batch_x, Y:batch_y, keep_prob:0.5, learning_rate:lr})\n",
    "    lr = lr * (1 - 0.001)\n",
    "    \n",
    "train_accuracy = 0\n",
    "for i in range(batch_per_epoch):\n",
    "    batch_x = get_batch(i, batchsize, trainimg)\n",
    "    batch_y = get_batch(i, batchsize, trainlabel)\n",
    "    train_accuracy += sess.run(accuracy, feed_dict={X:batch_x, Y:batch_y, keep_prob:1})\n",
    "        \n",
    "print (\"train complete : test accuracy = %.3f\" % (sess.run(accuracy, feed_dict={X:testimg, Y:testlabel, keep_prob:1})))\n",
    "print (\"                 train accuracy = %.3f\" % (train_accuracy / batch_per_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate\n",
      "0 :  2% (   1 /   60)     1 errors with o\n",
      "1 :  2% (   1 /   56)     1 errors with !\n",
      "2 :  0% (   0 /   58)     0 errors with 0\n",
      "3 :  0% (   0 /   70)     0 errors with 0\n",
      "4 :  0% (   0 /   67)     0 errors with 0\n",
      "5 :  1% (   1 /   67)     1 errors with >\n",
      "6 :  2% (   1 /   60)     1 errors with K\n",
      "7 :  2% (   1 /   45)     1 errors with R\n",
      "8 :  2% (   1 /   58)     1 errors with &\n",
      "9 :  0% (   0 /   58)     0 errors with 0\n",
      "a :  2% (   1 /   66)     1 errors with i\n",
      "b :  2% (   1 /   58)     1 errors with D\n",
      "c :  2% (   1 /   52)     1 errors with d\n",
      "d :  5% (   2 /   43)     1 errors with 4\n",
      "e :  0% (   0 /   70)     0 errors with 0\n",
      "f :  3% (   2 /   58)     1 errors with t\n",
      "g :  4% (   3 /   70)     2 errors with q\n",
      "h :  0% (   0 /   45)     0 errors with 0\n",
      "i : 16% (  10 /   64)     4 errors with I\n",
      "j :  2% (   1 /   64)     1 errors with f\n",
      "k :  2% (   1 /   53)     1 errors with K\n",
      "l : 37% (  20 /   54)    15 errors with I\n",
      "m :  0% (   0 /   56)     0 errors with 0\n",
      "n :  0% (   0 /   55)     0 errors with 0\n",
      "o :  3% (   2 /   68)     2 errors with c\n",
      "p :  2% (   1 /   64)     1 errors with g\n",
      "q :  0% (   0 /   53)     0 errors with 0\n",
      "r :  2% (   1 /   64)     1 errors with n\n",
      "s :  0% (   0 /   46)     0 errors with 0\n",
      "t :  8% (   5 /   64)     2 errors with 1\n",
      "u :  0% (   0 /   56)     0 errors with 0\n",
      "v :  0% (   0 /   59)     0 errors with 0\n",
      "w :  0% (   0 /   59)     0 errors with 0\n",
      "x :  2% (   1 /   62)     1 errors with k\n",
      "y :  0% (   0 /   58)     0 errors with 0\n",
      "z :  0% (   0 /   47)     0 errors with 0\n",
      "A :  0% (   0 /   59)     0 errors with 0\n",
      "B :  1% (   1 /   72)     1 errors with 8\n",
      "C :  2% (   1 /   63)     1 errors with c\n",
      "D :  2% (   1 /   56)     1 errors with R\n",
      "E :  2% (   1 /   44)     1 errors with B\n",
      "F :  4% (   2 /   48)     1 errors with f\n",
      "G :  0% (   0 /   60)     0 errors with 0\n",
      "H :  0% (   0 /   53)     0 errors with 0\n",
      "I : 29% (  16 /   56)    11 errors with l\n",
      "J : 16% (  10 /   61)     2 errors with I\n",
      "K :  0% (   0 /   51)     0 errors with 0\n",
      "L : 10% (   6 /   61)     3 errors with U\n",
      "M :  0% (   0 /   64)     0 errors with 0\n",
      "N :  0% (   0 /   55)     0 errors with 0\n",
      "O :  5% (   3 /   64)     2 errors with 0\n",
      "P :  3% (   2 /   70)     1 errors with 9\n",
      "Q :  3% (   2 /   62)     2 errors with O\n",
      "R :  0% (   0 /   57)     0 errors with 0\n",
      "S :  4% (   2 /   54)     1 errors with 5\n",
      "T :  0% (   0 /   51)     0 errors with 0\n",
      "U :  0% (   0 /   54)     0 errors with 0\n",
      "V :  0% (   0 /   51)     0 errors with 0\n",
      "W :  0% (   0 /   53)     0 errors with 0\n",
      "X :  0% (   0 /   45)     0 errors with 0\n",
      "Y :  0% (   0 /   61)     0 errors with 0\n",
      "Z :  0% (   0 /   62)     0 errors with 0\n",
      "( :  4% (   2 /   51)     2 errors with {\n",
      ") :  0% (   0 /   51)     0 errors with 0\n",
      "' :  2% (   1 /   49)     1 errors with \"\n",
      "\" :  5% (   3 /   61)     1 errors with '\n",
      ". :  8% (   5 /   66)     4 errors with ,\n",
      ", : 24% (  14 /   58)    13 errors with .\n",
      ": : 16% (  10 /   64)     9 errors with ;\n",
      "; :  8% (   4 /   52)     4 errors with :\n",
      "! :  7% (   3 /   44)     1 errors with 1\n",
      "? :  3% (   2 /   65)     1 errors with 7\n",
      "/ :  0% (   0 /   51)     0 errors with 0\n",
      "@ :  0% (   0 /   60)     0 errors with 0\n",
      "# :  0% (   0 /   54)     0 errors with 0\n",
      "$ :  2% (   1 /   48)     1 errors with S\n",
      "% :  0% (   0 /   51)     0 errors with 0\n",
      "^ :  0% (   0 /   56)     0 errors with 0\n",
      "& :  2% (   1 /   61)     1 errors with 8\n",
      "* :  2% (   1 /   47)     1 errors with \"\n",
      "[ :  6% (   3 /   52)     1 errors with 1\n",
      "] :  5% (   3 /   55)     1 errors with H\n",
      "{ :  3% (   1 /   38)     1 errors with [\n",
      "} :  3% (   2 /   60)     1 errors with )\n",
      "< :  0% (   0 /   54)     0 errors with 0\n",
      "> :  0% (   0 /   48)     0 errors with 0\n",
      "~ :  2% (   1 /   55)     1 errors with -\n",
      "- :  4% (   2 /   55)     1 errors with n\n"
     ]
    }
   ],
   "source": [
    "h = sess.run(hypothesis, feed_dict={X:testimg, Y:testlabel, keep_prob:1})\n",
    "y = testlabel\n",
    "n_error = np.zeros([y.shape[0], y.shape[0]])\n",
    "n_all = np.zeros(y.shape[0])\n",
    "\n",
    "for i in range(y.shape[0]):\n",
    "    n_all[np.argmax(y[i])] += 1\n",
    "    if (np.argmax(h[i]) != np.argmax(y[i])):\n",
    "        n_error[np.argmax(y[i])][np.argmax(h[i])] += 1\n",
    "\n",
    "        \n",
    "print (\"Error rate\")\n",
    "for i, ch in enumerate(en_chset):\n",
    "    most_error = np.argmax(n_error[i])\n",
    "    print (\"%s : %2.0f%% (%4d / %4d)\" %\n",
    "           (ch, float(np.sum(n_error[i])) / n_all[i] * 100, np.sum(n_error[i]), n_all[i]), end=\"\")\n",
    "    print (\"%6d errors with %s\" % (n_error[i][most_error], en_chset[most_error]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
