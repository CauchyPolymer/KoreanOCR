{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packs loaded\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import imread\n",
    "import json\n",
    "import gzip\n",
    "import tarfile\n",
    "import random\n",
    "from hangul_utils import split_syllable_char, split_syllables, join_jamos\n",
    "%matplotlib inline\n",
    "plt.rcParams['image.cmap'] = 'Greys'\n",
    "\n",
    "print(\"packs loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ko index loaded\n",
      "tar opened\n",
      " 0% complete (1 / 211500)\n",
      " 5% complete (10001 / 211500)\n",
      " 9% complete (20001 / 211500)\n",
      "14% complete (30001 / 211500)\n",
      "19% complete (40001 / 211500)\n",
      "24% complete (50001 / 211500)\n",
      "28% complete (60001 / 211500)\n",
      "33% complete (70001 / 211500)\n",
      "38% complete (80001 / 211500)\n",
      "43% complete (90001 / 211500)\n",
      "47% complete (100001 / 211500)\n",
      "52% complete (110001 / 211500)\n",
      "57% complete (120001 / 211500)\n",
      "61% complete (130001 / 211500)\n",
      "66% complete (140001 / 211500)\n",
      "71% complete (150001 / 211500)\n",
      "76% complete (160001 / 211500)\n",
      "80% complete (170001 / 211500)\n",
      "85% complete (180001 / 211500)\n",
      "90% complete (190001 / 211500)\n",
      "95% complete (200001 / 211500)\n",
      "99% complete (210001 / 211500)\n",
      "ko image loaded\n"
     ]
    }
   ],
   "source": [
    "index_data_ko = []\n",
    "\n",
    "with gzip.open('data/ko/index.json.gz', 'rt') as arc:\n",
    "    index_data_ko.extend(json.load(arc))\n",
    "    print(\"ko index loaded\")\n",
    "    \n",
    "with tarfile.open('data/ko/data.tar.gz', \"r|*\") as tar:\n",
    "    print(\"tar opened\")\n",
    "    img_data_ko = []\n",
    "    for i, member in enumerate(index_data_ko):\n",
    "        if i%10000 == 1:\n",
    "            print(\"%2.0f%% complete (%d / %d)\" % (i / len(index_data_ko) * 100, i, len(index_data_ko)))\n",
    "        ti = tar.next()\n",
    "        if ti.name != member['path']:\n",
    "            print(\"ERROR: order doesn't match\")\n",
    "            break;\n",
    "        f = tar.extractfile(ti)\n",
    "        img_data_ko.append(1 - (imread(f)/255))\n",
    "    img_ko = np.array(img_data_ko)\n",
    "    del img_data_ko\n",
    "    print(\"ko image loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ko label loaded\n"
     ]
    }
   ],
   "source": [
    "ko_chset_cho = [\"ㄱ\", \"ㄲ\", \"ㄴ\", \"ㄷ\", \"ㄸ\", \"ㄹ\", \"ㅁ\", \"ㅂ\", \"ㅃ\", \"ㅅ\", \"ㅆ\", \"ㅇ\", \"ㅈ\", \"ㅉ\", \"ㅊ\", \"ㅋ\", \"ㅌ\", \"ㅍ\", \"ㅎ\"]\n",
    "ko_chset_jung = [\"ㅏ\", \"ㅐ\", \"ㅑ\", \"ㅒ\", \"ㅓ\", \"ㅔ\", \"ㅕ\", \"ㅖ\", \"ㅗ\", \"ㅘ\", \"ㅙ\", \"ㅚ\", \"ㅛ\", \"ㅜ\", \"ㅝ\", \"ㅞ\", \"ㅟ\", \"ㅠ\", \"ㅡ\", \"ㅢ\", \"ㅣ\"]\n",
    "ko_chset_jong = [\"X\", \"ㄱ\", \"ㄲ\", \"ㄳ\", \"ㄴ\", \"ㄵ\", \"ㄶ\", \"ㄷ\", \"ㄹ\", \"ㄺ\", \"ㄻ\", \"ㄼ\", \"ㄽ\", \"ㄾ\", \"ㄿ\", \"ㅀ\", \"ㅁ\", \"ㅂ\", \"ㅄ\", \"ㅅ\", \"ㅆ\", \"ㅇ\", \"ㅈ\", \"ㅊ\", \"ㅋ\", \"ㅌ\", \"ㅍ\", \"ㅎ\"]\n",
    "\n",
    "label_ko_cho = np.zeros([img_ko.shape[0], len(ko_chset_cho)])\n",
    "label_ko_jung = np.zeros([img_ko.shape[0], len(ko_chset_jung)])\n",
    "label_ko_jong = np.zeros([img_ko.shape[0], len(ko_chset_jong)])\n",
    "for i, member in enumerate(index_data_ko):\n",
    "    splited = split_syllable_char(member['target'])\n",
    "    label_ko_cho[i][ko_chset_cho.index(splited[0])] = 1\n",
    "    label_ko_jung[i][ko_chset_jung.index(splited[1])] = 1\n",
    "    if len(splited) < 3:\n",
    "        label_ko_jong[i][0] = 1\n",
    "    else:\n",
    "        label_ko_jong[i][ko_chset_jong.index(splited[2])] = 1\n",
    "    \n",
    "print(\"ko label loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffled\n"
     ]
    }
   ],
   "source": [
    "def getIndex(l, indexes):\n",
    "    return [l[i] for i in indexes]\n",
    "\n",
    "def shuffle(n, *lists):\n",
    "    perm = np.random.permutation(n)\n",
    "    lists = list(lists)\n",
    "    for i in range(len(lists)):\n",
    "        if hasattr(lists[i], \"shape\"):\n",
    "            lists[i] = lists[i][perm]\n",
    "        else:\n",
    "            lists[i] = getIndex(lists[i], perm)\n",
    "    return tuple(lists)\n",
    "\n",
    "img_ko, label_ko_cho, label_ko_jung, label_ko_jong, index_data_ko = shuffle(\n",
    "    img_ko.shape[0], img_ko, label_ko_cho, label_ko_jung, label_ko_jong, index_data_ko)\n",
    "\n",
    "print(\"shuffled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(211500, 32, 32)\n",
      "{'target': '째', 'weight': 'BOLD', 'path': '0153664.png', 'font': 'NanumGothic'}\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.\n",
      "  0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD9CAYAAACcAsr/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3158238828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(img_ko.shape)\n",
    "plt.figure()\n",
    "plt.imshow(img_ko[0], interpolation='none')\n",
    "print(index_data_ko[0])\n",
    "print(label_ko_cho[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function loaded\n"
     ]
    }
   ],
   "source": [
    "trainimg = img_ko[:-5000]\n",
    "trainlabel_cho = label_ko_cho[:-5000]\n",
    "trainlabel_jung = label_ko_jung[:-5000]\n",
    "trainlabel_jong = label_ko_jong[:-5000]\n",
    "testimg = img_ko[-5000:]\n",
    "testlabel_cho = label_ko_cho[-5000:]\n",
    "testlabel_jung = label_ko_jung[-5000:]\n",
    "testlabel_jong = label_ko_jong[-5000:]\n",
    "randidx = np.random.randint(trainimg.shape[0], size=2)\n",
    "\n",
    "def get_batch(i, batch_size, input_var):\n",
    "    if batch_size > input_var.shape[0]:\n",
    "        return input_var\n",
    "    start = (i*batch_size)%input_var.shape[0]\n",
    "    overflow = start + batch_size - input_var.shape[0]\n",
    "    if overflow <= 0:\n",
    "        return input_var[start:start+batch_size]\n",
    "    else:\n",
    "        return np.r_[input_var[start:], input_var[:overflow]]\n",
    "    \n",
    "def build_cnn(cnn_shape, patch_shape, X):\n",
    "    n_before = int(X.get_shape()[3])\n",
    "    layer = X\n",
    "    for idx, val in enumerate(cnn_shape):\n",
    "        W = tf.Variable(tf.truncated_normal([patch_shape[0], patch_shape[1], n_before, val], stddev=0.1))\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[val]))\n",
    "        layer = tf.nn.relu(tf.nn.conv2d(layer, W, strides=[1, 1, 1, 1], padding='SAME') + b)\n",
    "        layer = tf.nn.max_pool(layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        n_before = val\n",
    "    layer_shape = layer.get_shape().as_list()\n",
    "    n_out = layer_shape[1] * layer_shape[2] * layer_shape[3]\n",
    "    return tf.reshape(layer, [-1, n_out])\n",
    "    \n",
    "def build_nn(shape, X, Y):\n",
    "    n_before = int(X.get_shape()[1])\n",
    "    n_out = int(Y.get_shape()[1])\n",
    "    layer = X\n",
    "    for idx, val in enumerate(shape):\n",
    "        W = tf.Variable(tf.truncated_normal([n_before, val], stddev=0.1))\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[val]))\n",
    "        layer = tf.nn.relu(tf.matmul(layer, W)+b)\n",
    "        n_before = val\n",
    "    W = tf.Variable(tf.truncated_normal([n_before, n_out], stddev=0.1))\n",
    "    b = tf.Variable(tf.constant(0.1, shape=[n_out]))\n",
    "    return tf.matmul(layer, W)+b\n",
    "\n",
    "print(\"function loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 32, 32])\n",
    "Y_cho = tf.placeholder(tf.float32, [None, len(ko_chset_cho)])\n",
    "Y_jung = tf.placeholder(tf.float32, [None, len(ko_chset_jung)])\n",
    "Y_jong = tf.placeholder(tf.float32, [None, len(ko_chset_jong)])\n",
    "\n",
    "cnn_layer = build_cnn([32, 64], [5,5], tf.reshape(X, [-1, 32, 32, 1]))\n",
    "dense_cho = build_nn([512], cnn_layer, Y_cho)\n",
    "dense_jung = build_nn([512], cnn_layer, Y_jung)\n",
    "dense_jong = build_nn([512], cnn_layer, Y_jong)\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "dropout_cho = tf.nn.dropout(dense_cho, keep_prob)\n",
    "dropout_jung = tf.nn.dropout(dense_jung, keep_prob)\n",
    "dropout_jong = tf.nn.dropout(dense_jong, keep_prob)\n",
    "h_cho = tf.nn.softmax(dropout_cho)\n",
    "h_jung = tf.nn.softmax(dropout_jung)\n",
    "h_jong = tf.nn.softmax(dropout_jong)\n",
    "\n",
    "learning_rate = tf.placeholder(tf.float32)\n",
    "cost_cho = tf.reduce_mean(-tf.reduce_sum(Y_cho * tf.log(h_cho), reduction_indices=[1]))\n",
    "cost_jung = tf.reduce_mean(-tf.reduce_sum(Y_jung * tf.log(h_jung), reduction_indices=[1]))\n",
    "cost_jong = tf.reduce_mean(-tf.reduce_sum(Y_jong * tf.log(h_jong), reduction_indices=[1]))\n",
    "\n",
    "train = tf.train.AdamOptimizer(learning_rate).minimize(cost_cho + cost_jung + cost_jong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 206500, mini-batch 30 * 6883\n",
      "     0th epoch : test accuracy = 0.000\n",
      "     0th epoch : test accuracy = 0.010\n",
      "     0th epoch : test accuracy = 0.053\n",
      "     0th epoch : test accuracy = 0.092\n",
      "     0th epoch : test accuracy = 0.174\n",
      "     0th epoch : test accuracy = 0.215\n",
      "     0th epoch : test accuracy = 0.285\n",
      "     0th epoch : test accuracy = 0.362\n",
      "     0th epoch : test accuracy = 0.410\n",
      "     0th epoch : test accuracy = 0.456\n",
      "     0th epoch : test accuracy = 0.487\n",
      "     0th epoch : test accuracy = 0.518\n",
      "     0th epoch : test accuracy = 0.572\n",
      "     0th epoch : test accuracy = 0.589\n",
      "     0th epoch : test accuracy = 0.628\n",
      "     0th epoch : test accuracy = 0.649\n",
      "     0th epoch : test accuracy = 0.659\n",
      "     0th epoch : test accuracy = 0.675\n",
      "     0th epoch : test accuracy = 0.705\n",
      "     0th epoch : test accuracy = 0.715\n",
      "     0th epoch : test accuracy = 0.729\n",
      "     0th epoch : test accuracy = 0.746\n",
      "     0th epoch : test accuracy = 0.737\n",
      "     0th epoch : test accuracy = 0.748\n",
      "     0th epoch : test accuracy = 0.773\n",
      "     0th epoch : test accuracy = 0.775\n",
      "     0th epoch : test accuracy = 0.786\n",
      "     0th epoch : test accuracy = 0.797\n",
      "     0th epoch : test accuracy = 0.816\n",
      "     0th epoch : test accuracy = 0.803\n",
      "     0th epoch : test accuracy = 0.815\n",
      "     0th epoch : test accuracy = 0.834\n",
      "     0th epoch : test accuracy = 0.834\n",
      "     0th epoch : test accuracy = 0.841\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3b8b48ec526b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m                                \u001b[0mY_jung\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_y_jung\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                                \u001b[0mY_jong\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_y_jong\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                                keep_prob:0.5, learning_rate:lr})\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.0003\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/csehome/northfolk28/.virtualenvs/tensor/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 372\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    373\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/csehome/northfolk28/.virtualenvs/tensor/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m       results = self._do_run(handle, target_list, unique_fetches,\n\u001b[0;32m--> 636\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    637\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m       \u001b[0;31m# The movers are no longer used. Delete them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/csehome/northfolk28/.virtualenvs/tensor/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    706\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 708\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    709\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/csehome/northfolk28/.virtualenvs/tensor/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    713\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/csehome/northfolk28/.virtualenvs/tensor/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    695\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    696\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "trainsize = trainimg.shape[0]\n",
    "batchsize = 30\n",
    "batch_per_epoch = int(trainsize/batchsize)\n",
    "print (\"Training %d, mini-batch %d * %d\" % (trainsize, batchsize, batch_per_epoch))\n",
    "\n",
    "correct_cho = tf.equal(tf.argmax(Y_cho,1), tf.argmax(h_cho,1))\n",
    "correct_jung = tf.equal(tf.argmax(Y_jung,1), tf.argmax(h_jung,1))\n",
    "correct_jong = tf.equal(tf.argmax(Y_jong,1), tf.argmax(h_jong,1))\n",
    "correct_all = tf.logical_and(tf.logical_and(correct_cho, correct_jung), correct_jong)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_all, tf.float32))\n",
    "\n",
    "lr = 0.0003\n",
    "for i in range(batch_per_epoch*5):\n",
    "    if i % 100 == 0 :\n",
    "        print (\"%6dth epoch : test accuracy = %.3f\" % \\\n",
    "               (i / batch_per_epoch, sess.run(accuracy, feed_dict={X:testimg,\n",
    "                                                                   Y_cho:testlabel_cho,\n",
    "                                                                   Y_jung:testlabel_jung,\n",
    "                                                                   Y_jong:testlabel_jong, keep_prob:1})))\n",
    "        \n",
    "    batch_x = get_batch(i, batchsize, trainimg)\n",
    "    batch_y_cho = get_batch(i, batchsize, trainlabel_cho)\n",
    "    batch_y_jung = get_batch(i, batchsize, trainlabel_jung)\n",
    "    batch_y_jong = get_batch(i, batchsize, trainlabel_jong)\n",
    "    sess.run(train, feed_dict={X:batch_x, Y_cho:batch_y_cho,\n",
    "                               Y_jung:batch_y_jung,\n",
    "                               Y_jong:batch_y_jong,\n",
    "                               keep_prob:0.5, learning_rate:lr})\n",
    "    lr = lr * (1 - 0.0003)\n",
    "    \n",
    "train_accuracy = 0\n",
    "for i in range(batch_per_epoch):\n",
    "    batch_x = get_batch(i, batchsize, trainimg)\n",
    "    batch_y_cho = get_batch(i, batchsize, trainlabel_cho)\n",
    "    batch_y_jung = get_batch(i, batchsize, trainlabel_jung)\n",
    "    batch_y_jong = get_batch(i, batchsize, trainlabel_jong)\n",
    "    train_accuracy += sess.run(accuracy, feed_dict={X:batch_x, Y_cho:batch_y_cho,\n",
    "                               Y_jung:batch_y_jung,\n",
    "                               Y_jong:batch_y_jong, keep_prob:1})\n",
    "        \n",
    "print (\"train complete : test accuracy = %.3f\" % (sess.run(accuracy, feed_dict={X:testimg,\n",
    "                                                                   Y_cho:testlabel_cho,\n",
    "                                                                   Y_jung:testlabel_jung,\n",
    "                                                                   Y_jong:testlabel_jong, keep_prob:1})))\n",
    "print (\"                 train accuracy = %.3f\" % (train_accuracy / batch_per_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
