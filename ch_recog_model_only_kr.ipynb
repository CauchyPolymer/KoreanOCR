{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packs loaded\n",
      "{\n",
      "  \"hb_port\": 37416,\n",
      "  \"shell_port\": 56665,\n",
      "  \"transport\": \"tcp\",\n",
      "  \"kernel_name\": \"\",\n",
      "  \"iopub_port\": 39579,\n",
      "  \"ip\": \"127.0.0.1\",\n",
      "  \"signature_scheme\": \"hmac-sha256\",\n",
      "  \"control_port\": 55576,\n",
      "  \"stdin_port\": 54117,\n",
      "  \"key\": \"db3a19fd-d241-4ad9-bc7d-3eb7092ce1bf\"\n",
      "}\n",
      "\n",
      "Paste the above JSON into a file, and connect with:\n",
      "    $> ipython <app> --existing <file>\n",
      "or, if you are local, you can connect with just:\n",
      "    $> ipython <app> --existing /run/user/128932/jupyter/kernel-77a0fd46-ca49-4d95-a850-3d607e6db076.json \n",
      "or even just:\n",
      "    $> ipython <app> --existing \n",
      "if this is the most recent IPython session you have started.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import imread\n",
    "import json\n",
    "import gzip\n",
    "import tarfile\n",
    "import random\n",
    "from hangul_utils import split_syllable_char, split_syllables, join_jamos\n",
    "%matplotlib inline\n",
    "plt.rcParams['image.cmap'] = 'Greys'\n",
    "\n",
    "print(\"packs loaded\")\n",
    "%connect_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ko index loaded\n",
      "tar opened\n",
      " 0% complete (1 / 211500)\n",
      " 5% complete (10001 / 211500)\n",
      " 9% complete (20001 / 211500)\n",
      "14% complete (30001 / 211500)\n",
      "19% complete (40001 / 211500)\n",
      "24% complete (50001 / 211500)\n",
      "28% complete (60001 / 211500)\n",
      "33% complete (70001 / 211500)\n",
      "38% complete (80001 / 211500)\n",
      "43% complete (90001 / 211500)\n",
      "47% complete (100001 / 211500)\n",
      "52% complete (110001 / 211500)\n",
      "57% complete (120001 / 211500)\n",
      "61% complete (130001 / 211500)\n",
      "66% complete (140001 / 211500)\n",
      "71% complete (150001 / 211500)\n",
      "76% complete (160001 / 211500)\n",
      "80% complete (170001 / 211500)\n",
      "85% complete (180001 / 211500)\n",
      "90% complete (190001 / 211500)\n",
      "95% complete (200001 / 211500)\n",
      "99% complete (210001 / 211500)\n",
      "ko image loaded\n"
     ]
    }
   ],
   "source": [
    "index_data_ko = []\n",
    "\n",
    "with gzip.open('data/ko/index.json.gz', 'rt') as arc:\n",
    "    index_data_ko.extend(json.load(arc))\n",
    "    print(\"ko index loaded\")\n",
    "    \n",
    "with tarfile.open('data/ko/data.tar.gz', \"r|*\") as tar:\n",
    "    print(\"tar opened\")\n",
    "    img_data_ko = []\n",
    "    for i, member in enumerate(index_data_ko):\n",
    "        if i%10000 == 1:\n",
    "            print(\"%2.0f%% complete (%d / %d)\" % (i / len(index_data_ko) * 100, i, len(index_data_ko)))\n",
    "        ti = tar.next()\n",
    "        if ti.name != member['path']:\n",
    "            print(\"ERROR: order doesn't match\")\n",
    "            break;\n",
    "        f = tar.extractfile(ti)\n",
    "        img_data_ko.append(1 - (imread(f)/255))\n",
    "    img_ko = np.array(img_data_ko)\n",
    "    del img_data_ko\n",
    "    print(\"ko image loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ko label loaded\n"
     ]
    }
   ],
   "source": [
    "ko_chset_cho = [\"ㄱ\", \"ㄲ\", \"ㄴ\", \"ㄷ\", \"ㄸ\", \"ㄹ\", \"ㅁ\", \"ㅂ\", \"ㅃ\", \"ㅅ\", \"ㅆ\", \"ㅇ\", \"ㅈ\", \"ㅉ\", \"ㅊ\", \"ㅋ\", \"ㅌ\", \"ㅍ\", \"ㅎ\"]\n",
    "ko_chset_jung = [\"ㅏ\", \"ㅐ\", \"ㅑ\", \"ㅒ\", \"ㅓ\", \"ㅔ\", \"ㅕ\", \"ㅖ\", \"ㅗ\", \"ㅘ\", \"ㅙ\", \"ㅚ\", \"ㅛ\", \"ㅜ\", \"ㅝ\", \"ㅞ\", \"ㅟ\", \"ㅠ\", \"ㅡ\", \"ㅢ\", \"ㅣ\"]\n",
    "ko_chset_jong = [\"X\", \"ㄱ\", \"ㄲ\", \"ㄳ\", \"ㄴ\", \"ㄵ\", \"ㄶ\", \"ㄷ\", \"ㄹ\", \"ㄺ\", \"ㄻ\", \"ㄼ\", \"ㄽ\", \"ㄾ\", \"ㄿ\", \"ㅀ\", \"ㅁ\", \"ㅂ\", \"ㅄ\", \"ㅅ\", \"ㅆ\", \"ㅇ\", \"ㅈ\", \"ㅊ\", \"ㅋ\", \"ㅌ\", \"ㅍ\", \"ㅎ\"]\n",
    "\n",
    "label_ko_cho = np.zeros([img_ko.shape[0], len(ko_chset_cho)])\n",
    "label_ko_jung = np.zeros([img_ko.shape[0], len(ko_chset_jung)])\n",
    "label_ko_jong = np.zeros([img_ko.shape[0], len(ko_chset_jong)])\n",
    "for i, member in enumerate(index_data_ko):\n",
    "    splited = split_syllable_char(member['target'])\n",
    "    label_ko_cho[i][ko_chset_cho.index(splited[0])] = 1\n",
    "    label_ko_jung[i][ko_chset_jung.index(splited[1])] = 1\n",
    "    if len(splited) < 3:\n",
    "        label_ko_jong[i][0] = 1\n",
    "    else:\n",
    "        label_ko_jong[i][ko_chset_jong.index(splited[2])] = 1\n",
    "        \n",
    "label_ko = np.concatenate((label_ko_cho, label_ko_jung, label_ko_jong), axis=1)\n",
    "del label_ko_cho\n",
    "del label_ko_jung\n",
    "del label_ko_jong\n",
    "    \n",
    "print(\"ko label loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffled\n"
     ]
    }
   ],
   "source": [
    "def getIndex(l, indexes):\n",
    "    return [l[i] for i in indexes]\n",
    "\n",
    "def shuffle(n, *lists):\n",
    "    perm = np.random.permutation(n)\n",
    "    lists = list(lists)\n",
    "    for i in range(len(lists)):\n",
    "        if hasattr(lists[i], \"shape\"):\n",
    "            lists[i] = lists[i][perm]\n",
    "        else:\n",
    "            lists[i] = getIndex(lists[i], perm)\n",
    "    return tuple(lists)\n",
    "\n",
    "img_ko, label_ko, index_data_ko = shuffle(\n",
    "    img_ko.shape[0], img_ko, label_ko, index_data_ko)\n",
    "\n",
    "print(\"shuffled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(211500, 32, 32)\n",
      "{'weight': 'BOLD', 'path': '0107277.png', 'target': '솰', 'font': 'Dotum'}\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD9CAYAAACcAsr/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb6c3b63710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(img_ko.shape)\n",
    "plt.figure()\n",
    "plt.imshow(img_ko[0], interpolation='none')\n",
    "print(index_data_ko[0])\n",
    "print(label_ko[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function loaded\n"
     ]
    }
   ],
   "source": [
    "trainimg = img_ko[:-5000]\n",
    "trainlabel = label_ko[:-5000]\n",
    "testimg = img_ko[-5000:]\n",
    "testlabel = label_ko[-5000:]\n",
    "randidx = np.random.randint(trainimg.shape[0], size=2)\n",
    "\n",
    "def get_batch(i, batch_size, input_var):\n",
    "    if batch_size > input_var.shape[0]:\n",
    "        return input_var\n",
    "    start = (i*batch_size)%input_var.shape[0]\n",
    "    overflow = start + batch_size - input_var.shape[0]\n",
    "    if overflow <= 0:\n",
    "        return input_var[start:start+batch_size]\n",
    "    else:\n",
    "        return np.r_[input_var[start:], input_var[:overflow]]\n",
    "    \n",
    "def flatten_cnn(layer):\n",
    "    layer_shape = layer.get_shape().as_list()\n",
    "    n_out = layer_shape[1] * layer_shape[2] * layer_shape[3]\n",
    "    return tf.reshape(layer, [-1, n_out])\n",
    "\n",
    "def build_nn(shape, X):\n",
    "    n_before = int(X.get_shape()[1])\n",
    "    W = tf.Variable(tf.truncated_normal([n_before, shape], stddev=0.1))\n",
    "    b = tf.Variable(tf.constant(0.1, shape=[shape]))\n",
    "    return tf.matmul(X, W)+b\n",
    "\n",
    "def build_cnn(cnn_shape, patch_shape, X, stride=1):\n",
    "    n_before = int(X.get_shape()[3])\n",
    "    W = tf.Variable(tf.truncated_normal([patch_shape[0], patch_shape[1], n_before, cnn_shape], stddev=0.1))\n",
    "    b = tf.Variable(tf.constant(0.1, shape=[cnn_shape]))\n",
    "    layer = tf.nn.relu(tf.nn.conv2d(X, W, strides=[1, stride, stride, 1], padding='SAME') + b)\n",
    "    return layer\n",
    "\n",
    "def max2d_pool(layer):\n",
    "    return tf.nn.max_pool(layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "print(\"function loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session loaded\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 32, 32])\n",
    "Y = tf.placeholder(tf.float32, [None, label_ko.shape[1]])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "Y_cho = tf.slice(Y, [0, 0], [-1, len(ko_chset_cho)])\n",
    "Y_jung = tf.slice(Y, [0, len(ko_chset_cho)], [-1, len(ko_chset_jung)])\n",
    "Y_jong = tf.slice(Y, [0, len(ko_chset_cho)+len(ko_chset_jung)], [-1, len(ko_chset_jong)])\n",
    "\n",
    "# Small inception model\n",
    "# http://laonple.blog.me/220704822964\n",
    "X_reshape = tf.reshape(X, [-1, 32, 32, 1])\n",
    "cnn_1_5 = build_cnn(12, [5,5], X_reshape)\n",
    "cnn_1_3 = build_cnn(36, [3,3], X_reshape)\n",
    "cnn_1_concat = tf.concat(3, [cnn_1_5, cnn_1_3])\n",
    "cnn_1_pool = max2d_pool(cnn_1_concat) # 16 * 16 * 48\n",
    "\n",
    "cnn_2_5 = build_cnn(18, [5,5], cnn_1_pool)\n",
    "cnn_2_3 = build_cnn(48, [3,3], cnn_1_pool)\n",
    "cnn_2_1 = build_cnn(30, [1,1], cnn_1_pool)\n",
    "cnn_2_concat = tf.concat(3, [cnn_2_5, cnn_2_3, cnn_2_1])\n",
    "cnn_2_pool = max2d_pool(cnn_2_concat) # 8 * 8 * 96\n",
    "\n",
    "cnn_3_5_reduce = build_cnn(18, [1,1], cnn_2_pool)\n",
    "cnn_3_5 = build_cnn(36, [5,5], cnn_3_5_reduce)\n",
    "cnn_3_3_reduce = build_cnn(64, [1,1], cnn_2_pool)\n",
    "cnn_3_3 = build_cnn(96, [3,3], cnn_3_3_reduce)\n",
    "cnn_3_1 = build_cnn(60, [1,1], cnn_2_pool)\n",
    "cnn_3_concat = tf.concat(3, [cnn_3_5, cnn_3_3, cnn_3_1])\n",
    "cnn_3_pool = max2d_pool(cnn_3_concat) # 4 * 4 * 192\n",
    "\n",
    "dense_1 = tf.nn.relu(build_nn(1024, flatten_cnn(cnn_3_pool)))\n",
    "dropout_1 = tf.nn.dropout(dense_1, keep_prob)\n",
    "\n",
    "logit = build_nn(label_ko.shape[1], dropout_1)\n",
    "logit_cho = tf.slice(logit, [0, 0], [-1, len(ko_chset_cho)])\n",
    "logit_jung = tf.slice(logit, [0, len(ko_chset_cho)], [-1, len(ko_chset_jung)])\n",
    "logit_jong = tf.slice(logit, [0, len(ko_chset_cho)+len(ko_chset_jung)], [-1, len(ko_chset_jong)])\n",
    "h_cho = tf.nn.softmax(logit_cho)\n",
    "h_jung = tf.nn.softmax(logit_jung)\n",
    "h_jong = tf.nn.softmax(logit_jong)\n",
    "\n",
    "learning_rate = tf.placeholder(tf.float32)\n",
    "cost_cho = tf.nn.softmax_cross_entropy_with_logits(logit_cho, Y_cho)\n",
    "cost_jung = tf.nn.softmax_cross_entropy_with_logits(logit_jung, Y_jung)\n",
    "cost_jong = tf.nn.softmax_cross_entropy_with_logits(logit_jong, Y_jong)\n",
    "cost = cost_cho + cost_jung * 1.5 + cost_jong * 0.5\n",
    "cost_mean = tf.reduce_mean(cost) # mean of batch set\n",
    "\n",
    "train = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "correct_cho = tf.equal(tf.argmax(Y_cho,1), tf.argmax(h_cho,1))\n",
    "correct_jung = tf.equal(tf.argmax(Y_jung,1), tf.argmax(h_jung,1))\n",
    "correct_jong = tf.equal(tf.argmax(Y_jong,1), tf.argmax(h_jong,1))\n",
    "correct_two = tf.logical_or(tf.logical_and(correct_cho, tf.logical_or(correct_jung, correct_jong)),\n",
    "                           tf.logical_and(correct_jung, correct_jong))\n",
    "correct_all = tf.logical_and(tf.logical_and(correct_cho, correct_jung), correct_jong)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_all, tf.float32))\n",
    "accuracy_two = tf.reduce_mean(tf.cast(correct_two, tf.float32))\n",
    "accuracy_cho = tf.reduce_mean(tf.cast(correct_cho, tf.float32))\n",
    "accuracy_jung = tf.reduce_mean(tf.cast(correct_jung, tf.float32))\n",
    "accuracy_jong = tf.reduce_mean(tf.cast(correct_jong, tf.float32))\n",
    "\n",
    "sess = tf.Session()\n",
    "print(\"session loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def init_session():\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    print(\"session initialized\")\n",
    "    \n",
    "def train_accuracy():\n",
    "    trainsize = trainimg.shape[0]\n",
    "    batchsize = 100\n",
    "    batch_per_epoch = int(trainsize/batchsize)\n",
    "    train_accuracy = 0\n",
    "    for i in range(batch_per_epoch):\n",
    "        batch_x = get_batch(i, batchsize, trainimg)\n",
    "        batch_y = get_batch(i, batchsize, trainlabel)\n",
    "        train_accuracy += sess.run(accuracy, feed_dict={X:batch_x, Y:batch_y, keep_prob:1})\n",
    "    return train_accuracy / batch_per_epoch\n",
    "    \n",
    "def print_accuracy():\n",
    "    taccuracy, taccuracy_cho, taccuracy_jung, taccuracy_jong, taccuracy_two = \\\n",
    "            sess.run((accuracy, accuracy_cho, accuracy_jung, accuracy_jong, accuracy_two), feed_dict={X:testimg, Y:testlabel, keep_prob:1})\n",
    "    print (\"test accuracy = %.3f\" % taccuracy)\n",
    "    print (\"two of three = %.3f\" % taccuracy_two)\n",
    "    print (\"cho = %.3f\" % taccuracy_cho)\n",
    "    print (\"jung = %.3f\" % taccuracy_jung)\n",
    "    print (\"jong = %.3f\" % taccuracy_jong)\n",
    "    print (\"train accuracy = %.3f\" % train_accuracy())\n",
    "\n",
    "def do_training(is_console=False, lr_init = 0.003):\n",
    "    trainsize = trainimg.shape[0]\n",
    "    batchsize = 100\n",
    "    batch_per_epoch = int(trainsize/batchsize)\n",
    "    print (\"Training %d, mini-batch %d * %d\" % (trainsize, batchsize, batch_per_epoch))\n",
    "\n",
    "    lr = lr_init\n",
    "    for i in range(batch_per_epoch*5):\n",
    "        if i % 200 == 0 :\n",
    "            taccuracy, taccuracy_cho, taccuracy_jung, taccuracy_jong, taccuracy_two = \\\n",
    "            sess.run((accuracy, accuracy_cho, accuracy_jung, accuracy_jong, accuracy_two), feed_dict={X:testimg, Y:testlabel, keep_prob:1})\n",
    "            print (\"%6dth epoch : test accuracy = %.3f                  \" % \\\n",
    "                   (i / batch_per_epoch, taccuracy))\n",
    "            \n",
    "        if i % batch_per_epoch == 0 :\n",
    "            print (\"                 two of three = %.3f\" % taccuracy_two)\n",
    "            print (\"                 cho = %.3f\" % taccuracy_cho)\n",
    "            print (\"                 jung = %.3f\" % taccuracy_jung)\n",
    "            print (\"                 jong = %.3f\" % taccuracy_jong)\n",
    "\n",
    "        batch_x = get_batch(i, batchsize, trainimg)\n",
    "        batch_y = get_batch(i, batchsize, trainlabel)\n",
    "        cur_cost = sess.run((train, cost_mean), feed_dict={X:batch_x, Y:batch_y, keep_prob:0.5, learning_rate:lr})[1]\n",
    "        if(is_console):\n",
    "            print (\"%dth... lr = %.2e, cost = %.2e\\r\" % (i, lr, cur_cost), end=\"\")\n",
    "        lr = lr * (1 - 0.0003)\n",
    "    print(\"train complete--------------------------------\")\n",
    "    print_accuracy()\n",
    "    \n",
    "def error_check(pred_label_tuple):\n",
    "    h, y = pred_label_tuple\n",
    "    n_error = np.zeros([y.shape[0], y.shape[0]])\n",
    "    n_all = np.zeros(y.shape[0])\n",
    "\n",
    "    for i in range(y.shape[0]):\n",
    "        n_all[np.argmax(y[i])] += 1\n",
    "        if (np.argmax(h[i]) != np.argmax(y[i])):\n",
    "            n_error[np.argmax(y[i])][np.argmax(h[i])] += 1\n",
    "\n",
    "\n",
    "    print (\"Error rate\")\n",
    "    for i, ch in enumerate(ko_chset_jung):\n",
    "        most_error = np.argmax(n_error[i])\n",
    "        print (\"%s : %2.0f%% (%4d / %4d)\" %\n",
    "               (ch, float(np.sum(n_error[i])) / n_all[i] * 100, np.sum(n_error[i]), n_all[i]), end=\"\")\n",
    "        if n_error[i][most_error] > 0:\n",
    "            print (\"%6d errors with %s\" % (n_error[i][most_error], ko_chset_jung[most_error]))\n",
    "        else:\n",
    "            print (\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy = 0.997\n",
      "two of three = 1.000\n",
      "cho = 1.000\n",
      "jung = 0.998\n",
      "jong = 0.999\n",
      "train accuracy = 0.999\n"
     ]
    }
   ],
   "source": [
    "print_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate\n",
      "ㅏ :  0% (   0 /  490)\n",
      "ㅐ :  0% (   0 /  376)\n",
      "ㅑ :  0% (   0 /  152)\n",
      "ㅒ :  0% (   0 /   38)\n",
      "ㅓ :  0% (   1 /  421)     1 errors with ㅕ\n",
      "ㅔ :  0% (   0 /  290)\n",
      "ㅕ :  0% (   0 /  271)\n",
      "ㅖ :  1% (   1 /   75)     1 errors with ㅔ\n",
      "ㅗ :  0% (   1 /  400)     1 errors with ㅡ\n",
      "ㅘ :  0% (   0 /  171)\n",
      "ㅙ :  0% (   0 /   95)\n",
      "ㅚ :  0% (   0 /  215)\n",
      "ㅛ :  1% (   1 /  137)     1 errors with ㅡ\n",
      "ㅜ :  0% (   0 /  379)\n",
      "ㅝ :  0% (   0 /  126)\n",
      "ㅞ :  0% (   0 /   89)\n",
      "ㅟ :  0% (   0 /  214)\n",
      "ㅠ :  0% (   0 /  190)\n",
      "ㅡ :  1% (   2 /  398)     2 errors with ㅜ\n",
      "ㅢ :  0% (   0 /   79)\n",
      "ㅣ :  1% (   4 /  394)     4 errors with ㅏ\n"
     ]
    }
   ],
   "source": [
    "error_check(sess.run((h_jung, Y_jung), feed_dict={X:testimg, Y:testlabel, keep_prob:1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
