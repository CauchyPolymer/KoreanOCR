{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packs loaded\n",
      "{\n",
      "  \"kernel_name\": \"\",\n",
      "  \"control_port\": 47973,\n",
      "  \"signature_scheme\": \"hmac-sha256\",\n",
      "  \"ip\": \"127.0.0.1\",\n",
      "  \"stdin_port\": 45915,\n",
      "  \"hb_port\": 60977,\n",
      "  \"transport\": \"tcp\",\n",
      "  \"key\": \"3c5feff9-748c-48d7-98ac-57fca9771f5b\",\n",
      "  \"iopub_port\": 58001,\n",
      "  \"shell_port\": 56801\n",
      "}\n",
      "\n",
      "Paste the above JSON into a file, and connect with:\n",
      "    $> jupyter <app> --existing <file>\n",
      "or, if you are local, you can connect with just:\n",
      "    $> jupyter <app> --existing kernel-41ba424a-e845-42b8-a4de-0e5ac1e6d863.json\n",
      "or even just:\n",
      "    $> jupyter <app> --existing\n",
      "if this is the most recent Jupyter kernel you have started.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import data\n",
    "from data import en_chset, ko_chset_cho, ko_chset_jung, ko_chset_jong\n",
    "%matplotlib inline\n",
    "plt.rcParams['image.cmap'] = 'Greys'\n",
    "\n",
    "print(\"packs loaded\")\n",
    "%connect_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index loaded\n",
      "tar opened\n",
      " 0% complete (1 / 7920)\n",
      "image loaded\n",
      "index loaded\n",
      "tar opened\n",
      " 0% complete (1 / 21150)\n",
      "47% complete (10001 / 21150)\n",
      "95% complete (20001 / 21150)\n",
      "image loaded\n",
      "label loaded\n",
      "shuffled\n"
     ]
    }
   ],
   "source": [
    "index_data, img, label = data.get_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BatchBuffer:\n",
    "    def __init__(self, offset, size):\n",
    "        self.offset = offset\n",
    "        self.size = size\n",
    "        self.index = 0\n",
    "    \n",
    "    def read(self, num=None):\n",
    "        raise NotImplementedError('Unimplemented')\n",
    "        \n",
    "    def seek(self, num, mode=0):\n",
    "        if mode == 0:\n",
    "            self.index = self.offset+num\n",
    "        elif mode == 1:\n",
    "            self.index += num\n",
    "        elif mode == 2:\n",
    "            self.index = self.offset+self.size+num\n",
    "        else:\n",
    "            raise NotImplementedError('Unimplemented')\n",
    "        \n",
    "    def tell(self):\n",
    "        return self.index\n",
    "\n",
    "class ArrayBuffer(BatchBuffer):\n",
    "    def __init__(self, array, offset, size):\n",
    "        if size < 0:\n",
    "            size = len(array) - offset\n",
    "        super().__init__(offset, size)\n",
    "        self.array = array\n",
    "    \n",
    "    def read(self, num=None):\n",
    "        if self.index >= self.size:\n",
    "            return -1\n",
    "        \n",
    "        if num is None:\n",
    "            num = self.size - self.index\n",
    "            \n",
    "        ni = self.index+num\n",
    "        if ni >= self.size:\n",
    "            ni = self.size\n",
    "        ret = self.array[self.offset+self.index:self.offset+ni-1]\n",
    "        self.index += num\n",
    "        return ret\n",
    "\n",
    "trainimg = ArrayBuffer(img, 15000, -1)\n",
    "trainlabel = ArrayBuffer(label, 15000, -1)\n",
    "testimg = ArrayBuffer(img, 0, 12000)\n",
    "testlabel = ArrayBuffer(label, 0, 12000)\n",
    "cvimg = ArrayBuffer(img, 12000, 3000)\n",
    "cvlabel = ArrayBuffer(label, 12000, 3000)\n",
    "randidx = np.random.randint(trainimg.size, size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29070, 32, 32)\n",
      "{'font': 'Batang', 'target': '앵', 'path': '0012398.png', 'weight': 'NORMAL'}\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      "15000\n",
      "14070\n",
      "15000\n",
      "-1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFfCAYAAACfj30KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYUlKZAhLUiJDWJISGcKSlMgQlqRE/x/ri6M+tmoUhAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fba2f5db128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(img.shape)\n",
    "plt.figure()\n",
    "plt.imshow(img[0], interpolation='none')\n",
    "print(index_data[0])\n",
    "print(label[0])\n",
    "\n",
    "trainlabel.seek(0)\n",
    "print(trainlabel.offset)\n",
    "print(trainlabel.size)\n",
    "print(trainlabel.index)\n",
    "print(trainlabel.read(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function loaded\n"
     ]
    }
   ],
   "source": [
    "def flatten_cnn(layer):\n",
    "    layer_shape = layer.get_shape().as_list()\n",
    "    n_out = layer_shape[1] * layer_shape[2] * layer_shape[3]\n",
    "    return tf.reshape(layer, [-1, n_out])\n",
    "\n",
    "def build_nn(shape, X, name):\n",
    "    n_before = int(X.get_shape()[1])\n",
    "    W = tf.Variable(tf.truncated_normal([n_before, shape], stddev=0.1), name=name+\"_W\")\n",
    "    b = tf.Variable(tf.constant(0.1, shape=[shape]), name=name+\"_b\")\n",
    "    return tf.matmul(X, W)+b\n",
    "\n",
    "def build_cnn(cnn_shape, patch_shape, X, name, stride=1):\n",
    "    n_before = int(X.get_shape()[3])\n",
    "    W = tf.Variable(tf.truncated_normal([patch_shape[0], patch_shape[1], n_before, cnn_shape], stddev=0.1),\n",
    "                   name=name+\"_W\")\n",
    "    b = tf.Variable(tf.constant(0.1, shape=[cnn_shape]), name=name+\"_b\")\n",
    "    layer = tf.nn.relu(tf.nn.conv2d(X, W, strides=[1, stride, stride, 1], padding='SAME') + b)\n",
    "    return layer\n",
    "\n",
    "def max2d_pool(layer):\n",
    "    return tf.nn.max_pool(layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def slice_label(tf_label, len_tuple):\n",
    "    cur = 0\n",
    "    sliced = []\n",
    "    for l in len_tuple:\n",
    "        sliced.append(tf.slice(tf_label, [0, cur], [-1, l]))\n",
    "        cur += l\n",
    "    return tuple(sliced)\n",
    "\n",
    "print(\"function loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn_1_5_W:0\n",
      "cnn_1_5_b:0\n",
      "cnn_1_3_W:0\n",
      "cnn_1_3_b:0\n",
      "cnn_2_5_W:0\n",
      "cnn_2_5_b:0\n",
      "cnn_2_3_W:0\n",
      "cnn_2_3_b:0\n",
      "cnn_2_1_W:0\n",
      "cnn_2_1_b:0\n",
      "cnn_3_5_reduce_W:0\n",
      "cnn_3_5_reduce_b:0\n",
      "cnn_3_5_W:0\n",
      "cnn_3_5_b:0\n",
      "cnn_3_3_reduce_W:0\n",
      "cnn_3_3_reduce_b:0\n",
      "cnn_3_3_W:0\n",
      "cnn_3_3_b:0\n",
      "cnn_3_1_W:0\n",
      "cnn_3_1_b:0\n",
      "dense_1_W:0\n",
      "dense_1_b:0\n",
      "logit_W:0\n",
      "logit_b:0\n",
      "session loaded\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, [None, 32, 32])\n",
    "Y = tf.placeholder(tf.float32, [None, 160])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "Y_cho, Y_jung, Y_jong, Y_en = slice_label(Y,\n",
    "                                         (len(ko_chset_cho)+1,\n",
    "                                         len(ko_chset_jung)+1,\n",
    "                                         len(ko_chset_jong)+1,\n",
    "                                         len(en_chset)+1))\n",
    "# Small inception model\n",
    "# http://laonple.blog.me/220704822964\n",
    "X_reshape = tf.reshape(X, [-1, 32, 32, 1])\n",
    "cnn_1_5 = build_cnn(12, [5,5], X_reshape, \"cnn_1_5\")\n",
    "cnn_1_3 = build_cnn(36, [3,3], X_reshape, \"cnn_1_3\")\n",
    "cnn_1_concat = tf.concat(3, [cnn_1_5, cnn_1_3])\n",
    "cnn_1_pool = max2d_pool(cnn_1_concat) # 16 * 16 * 48\n",
    "\n",
    "cnn_2_5 = build_cnn(18, [5,5], cnn_1_pool, \"cnn_2_5\")\n",
    "cnn_2_3 = build_cnn(48, [3,3], cnn_1_pool, \"cnn_2_3\")\n",
    "cnn_2_1 = build_cnn(30, [1,1], cnn_1_pool, \"cnn_2_1\")\n",
    "cnn_2_concat = tf.concat(3, [cnn_2_5, cnn_2_3, cnn_2_1])\n",
    "cnn_2_pool = max2d_pool(cnn_2_concat) # 8 * 8 * 96\n",
    "\n",
    "cnn_3_5_reduce = build_cnn(18, [1,1], cnn_2_pool, \"cnn_3_5_reduce\")\n",
    "cnn_3_5 = build_cnn(36, [5,5], cnn_3_5_reduce, \"cnn_3_5\")\n",
    "cnn_3_3_reduce = build_cnn(64, [1,1], cnn_2_pool, \"cnn_3_3_reduce\")\n",
    "cnn_3_3 = build_cnn(96, [3,3], cnn_3_3_reduce, \"cnn_3_3\")\n",
    "cnn_3_1 = build_cnn(60, [1,1], cnn_2_pool, \"cnn_3_1\")\n",
    "cnn_3_concat = tf.concat(3, [cnn_3_5, cnn_3_3, cnn_3_1])\n",
    "cnn_3_pool = max2d_pool(cnn_3_concat) # 4 * 4 * 192\n",
    "\n",
    "dense_1 = tf.nn.relu(build_nn(1024, flatten_cnn(cnn_3_pool), \"dense_1\"))\n",
    "dropout_1 = tf.nn.dropout(dense_1, keep_prob)\n",
    "\n",
    "logit = build_nn(160, dropout_1, \"logit\")\n",
    "logit_cho, logit_jung, logit_jong, logit_en = slice_label(logit,\n",
    "                                         (len(ko_chset_cho)+1,\n",
    "                                         len(ko_chset_jung)+1,\n",
    "                                         len(ko_chset_jong)+1,\n",
    "                                         len(en_chset)+1))\n",
    "h_cho = tf.nn.softmax(logit_cho)\n",
    "h_jung = tf.nn.softmax(logit_jung)\n",
    "h_jong = tf.nn.softmax(logit_jong)\n",
    "h_en = tf.nn.softmax(logit_en)\n",
    "\n",
    "learning_rate = tf.placeholder(tf.float32)\n",
    "cost_cho = tf.nn.softmax_cross_entropy_with_logits(logit_cho, Y_cho)\n",
    "cost_jung = tf.nn.softmax_cross_entropy_with_logits(logit_jung, Y_jung)\n",
    "cost_jong = tf.nn.softmax_cross_entropy_with_logits(logit_jong, Y_jong)\n",
    "cost_en = tf.nn.softmax_cross_entropy_with_logits(logit_en, Y_en)\n",
    "cost = cost_cho + cost_jung * 1.5 + cost_jong * 0.5 + cost_en\n",
    "cost_mean = tf.reduce_mean(cost) # mean of batch set\n",
    "\n",
    "var_before_adam = tf.all_variables()\n",
    "\n",
    "train = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "correct_cho = tf.equal(tf.argmax(Y_cho,1), tf.argmax(h_cho,1))\n",
    "correct_jung = tf.equal(tf.argmax(Y_jung,1), tf.argmax(h_jung,1))\n",
    "correct_jong = tf.equal(tf.argmax(Y_jong,1), tf.argmax(h_jong,1))\n",
    "correct_two = tf.logical_or(tf.logical_and(correct_cho, tf.logical_or(correct_jung, correct_jong)),\n",
    "                           tf.logical_and(correct_jung, correct_jong))\n",
    "correct_ko = tf.logical_and(tf.logical_and(correct_cho, correct_jung), correct_jong)\n",
    "correct_en = tf.equal(tf.argmax(Y_en,1), tf.argmax(h_en,1))\n",
    "correct_all = tf.logical_and(correct_ko, correct_en)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_all, tf.float32))\n",
    "accuracy_two = tf.reduce_mean(tf.cast(correct_two, tf.float32))\n",
    "accuracy_cho = tf.reduce_mean(tf.cast(correct_cho, tf.float32))\n",
    "accuracy_jung = tf.reduce_mean(tf.cast(correct_jung, tf.float32))\n",
    "accuracy_jong = tf.reduce_mean(tf.cast(correct_jong, tf.float32))\n",
    "accuracy_ko = tf.reduce_mean(tf.cast(correct_ko, tf.float32))\n",
    "accuracy_en = tf.reduce_mean(tf.cast(correct_en, tf.float32))\n",
    "\n",
    "sess = tf.Session()\n",
    "for v in var_before_adam:\n",
    "    print (v.name)\n",
    "print(\"session loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf function loaded\n"
     ]
    }
   ],
   "source": [
    "def init_session():\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    print(\"session initialized\")\n",
    "\n",
    "def get_accuracy_no_batch(imgset, labelset):\n",
    "    return sess.run((accuracy, accuracy_cho, accuracy_jung, accuracy_jong, accuracy_two, accuracy_en),\n",
    "                                        feed_dict={X:imgset, Y:labelset, keep_prob:1})\n",
    "\n",
    "def get_accuracy(imgbuf, labelbuf, batch=True):\n",
    "    imgbuf.seek(0)\n",
    "    labelbuf.seek(0)\n",
    "    \n",
    "    if batch:\n",
    "        temp_tuple = 0, 0, 0, 0, 0, 0\n",
    "        i = 0\n",
    "        while(True):\n",
    "            batch_x = imgbuf.read(100)\n",
    "            batch_y = labelbuf.read(100)\n",
    "            temp_tuple = tuple([item1 + item2 * batch_x.shape[0] for item1, item2 in\n",
    "                                zip(temp_tuple,\n",
    "                                    get_accuracy_no_batch(batch_x, batch_y))])\n",
    "            i += batch_x.shape[0]\n",
    "        tacc, tacc_cho, tacc_jung, tacc_jong, tacc_two, tacc_en = tuple([item / i for item in temp_tuple])\n",
    "    else:\n",
    "        tacc, tacc_cho, tacc_jung, tacc_jong, tacc_two, tacc_en = get_accuracy_no_batch(imgbuf.read(), labelbuf.read())\n",
    "    return tacc, tacc_cho, tacc_jung, tacc_jong, tacc_two, tacc_en\n",
    "    \n",
    "def print_accuracy(imgbuf, labelbuf, batch=True):\n",
    "    tacc, tacc_cho, tacc_jung, tacc_jong, tacc_two, tacc_en = get_accuracy(imgbuf, labelbuf, batch)\n",
    "    print (\"overall accuracy = %.3f                          \" % tacc)\n",
    "    print (\"two of three = %.3f\" % tacc_two)\n",
    "    print (\"cho = %.3f\" % tacc_cho)\n",
    "    print (\"jung = %.3f\" % tacc_jung)\n",
    "    print (\"jong = %.3f\" % tacc_jong)\n",
    "    print (\"en = %.3f\" % tacc_en)\n",
    "\n",
    "def do_training(is_console=False, lr_init = 0.003):\n",
    "    trainsize = trainimg.size\n",
    "    batchsize = 100\n",
    "    batch_per_epoch = int(trainsize/batchsize)\n",
    "    print (\"Training %d, mini-batch %d * %d\" % (trainsize, batchsize, batch_per_epoch))\n",
    "    epoch = 0\n",
    "\n",
    "    i = 0\n",
    "    lr = lr_init\n",
    "    while (epoch < 5):\n",
    "        if i % 200 == 0 :\n",
    "            tacc = get_accuracy(cvimg, cvlabel, True)[0]\n",
    "            print (\"%6dth epoch : cv accuracy = %.3f                  \" % (epoch, tacc))\n",
    "\n",
    "        batch_x = trainimg.read(batchsize)\n",
    "        batch_y = trainlabel.read(batchsize)\n",
    "        \n",
    "        if batch_x == -1:\n",
    "            print_accuracy(testimg, testlabel, True)\n",
    "            trainimg.seek(0)\n",
    "            trainlabel.seek(0)\n",
    "            epoch += 1\n",
    "            continue\n",
    "        \n",
    "        cur_cost = sess.run((train, cost_mean), feed_dict={X:batch_x, Y:batch_y, keep_prob:0.5, learning_rate:lr})[1]\n",
    "        if(is_console):\n",
    "            print (\"%dth... lr = %.2e, cost = %.2e\\r\" % (i, lr, cur_cost), end=\"\")\n",
    "        lr = lr * (1 - 0.0003)\n",
    "        i += 1\n",
    "        \n",
    "    print(\"train complete--------------------------------\")\n",
    "    print(\"test accuracy ---\")\n",
    "    print_accuracy(testimg, testlabel, True)\n",
    "    print(\"train accuracy ---\")\n",
    "    print_accuracy(trainimg, trainlabel, True)\n",
    "    \n",
    "def error_check(chset, pred_tf, label_tf, imgbuf, labelbuf):\n",
    "    label_len = label_tf.get_shape()[1]\n",
    "    n_error = np.zeros([label_len, label_len])\n",
    "    n_all = np.zeros(label_len)\n",
    "    new_chset = chset + [\"inv\"]\n",
    "    \n",
    "    batchsize = 100\n",
    "    \n",
    "    imgbuf.seek(0)\n",
    "    labelbuf.seek(0)\n",
    "    while(True):\n",
    "        batch_x = imgbuf.read(batchsize)\n",
    "        batch_y = labelbuf.read(batchsize)\n",
    "        if batch_x == -1:\n",
    "            break\n",
    "        batchsize = batch_x.shape[0]\n",
    "        h, y = sess.run((pred_tf, label_tf), feed_dict={X:batch_x, Y:batch_y, keep_prob:1})\n",
    "        for j in range(batchsize):\n",
    "            n_all[np.argmax(y[j])] += 1\n",
    "            if (np.argmax(h[j]) != np.argmax(y[j])):\n",
    "                n_error[np.argmax(y[j])][np.argmax(h[j])] += 1\n",
    "\n",
    "    print (\"Error rate\")\n",
    "    for i, ch in enumerate(new_chset):\n",
    "        most_error = np.argmax(n_error[i])\n",
    "        print (\"%s : %2.0f%% (%4d / %4d)\" %\n",
    "               (ch, float(np.sum(n_error[i])) / n_all[i] * 100, np.sum(n_error[i]), n_all[i]), end=\"\")\n",
    "        if n_error[i][most_error] > 0:\n",
    "            print (\"%6d errors with %s\" % (n_error[i][most_error], new_chset[most_error]))\n",
    "        else:\n",
    "            print (\"\")\n",
    "            \n",
    "def save_ckpt(path):\n",
    "    saver = tf.train.Saver(var_before_adam)\n",
    "    saver.save(sess, path)\n",
    "    print(\"ckpt saved\")\n",
    "    \n",
    "def load_ckpt(path):\n",
    "    saver = tf.train.Saver(var_before_adam)\n",
    "    saver.restore(sess, path)\n",
    "    print(\"ckpt loaded\")\n",
    "            \n",
    "print(\"tf function loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall accuracy = 0.997                          \n",
      "two of three = 1.000\n",
      "cho = 1.000\n",
      "jung = 0.999\n",
      "jong = 1.000\n",
      "en = 0.999\n"
     ]
    }
   ],
   "source": [
    "print_accuracy(testimg, testlabel, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate\n",
      "0 :  0% (   0 /   34)\n",
      "1 :  0% (   0 /   28)\n",
      "2 :  0% (   0 /   39)\n",
      "3 :  0% (   0 /   34)\n",
      "4 :  0% (   0 /   38)\n",
      "5 :  0% (   0 /   45)\n",
      "6 :  0% (   0 /   40)\n",
      "7 :  0% (   0 /   29)\n",
      "8 :  0% (   0 /   47)\n",
      "9 :  0% (   0 /   37)\n",
      "a :  0% (   0 /   35)\n",
      "b :  0% (   0 /   44)\n",
      "c :  0% (   0 /   40)\n",
      "d :  0% (   0 /   45)\n",
      "e :  0% (   0 /   33)\n",
      "f :  0% (   0 /   33)\n",
      "g :  0% (   0 /   30)\n",
      "h :  0% (   0 /   36)\n",
      "i :  3% (   1 /   39)     1 errors with I\n",
      "j :  0% (   0 /   44)\n",
      "k :  0% (   0 /   40)\n",
      "l : 20% (   6 /   30)     4 errors with 1\n",
      "m :  0% (   0 /   34)\n",
      "n :  0% (   0 /   37)\n",
      "o :  0% (   0 /   38)\n",
      "p :  0% (   0 /   33)\n",
      "q :  0% (   0 /   35)\n",
      "r :  0% (   0 /   46)\n",
      "s :  0% (   0 /   38)\n",
      "t :  0% (   0 /   36)\n",
      "u :  0% (   0 /   32)\n",
      "v :  0% (   0 /   28)\n",
      "w :  0% (   0 /   31)\n",
      "x :  0% (   0 /   48)\n",
      "y :  0% (   0 /   40)\n",
      "z :  0% (   0 /   32)\n",
      "A :  0% (   0 /   42)\n",
      "B :  0% (   0 /   36)\n",
      "C :  0% (   0 /   35)\n",
      "D :  0% (   0 /   42)\n",
      "E :  0% (   0 /   38)\n",
      "F :  0% (   0 /   45)\n",
      "G :  0% (   0 /   45)\n",
      "H :  0% (   0 /   37)\n",
      "I : 18% (   7 /   39)     7 errors with l\n",
      "J :  0% (   0 /   46)\n",
      "K :  0% (   0 /   35)\n",
      "L :  0% (   0 /   38)\n",
      "M :  0% (   0 /   53)\n",
      "N :  0% (   0 /   42)\n",
      "O :  0% (   0 /   34)\n",
      "P :  0% (   0 /   46)\n",
      "Q :  0% (   0 /   38)\n",
      "R :  0% (   0 /   32)\n",
      "S :  0% (   0 /   30)\n",
      "T :  0% (   0 /   33)\n",
      "U :  0% (   0 /   33)\n",
      "V :  0% (   0 /   39)\n",
      "W :  0% (   0 /   38)\n",
      "X :  0% (   0 /   39)\n",
      "Y :  0% (   0 /   35)\n",
      "Z :  0% (   0 /   33)\n",
      "( :  0% (   0 /   43)\n",
      ") :  0% (   0 /   35)\n",
      "' :  0% (   0 /   30)\n",
      "\" :  2% (   1 /   43)     1 errors with '\n",
      ". :  0% (   0 /   48)\n",
      ", :  0% (   0 /   29)\n",
      ": :  0% (   0 /   40)\n",
      "; :  0% (   0 /   37)\n",
      "! :  0% (   0 /   30)\n",
      "? :  0% (   0 /   28)\n",
      "/ :  0% (   0 /   32)\n",
      "@ :  0% (   0 /   37)\n",
      "# :  0% (   0 /   36)\n",
      "$ :  0% (   0 /   36)\n",
      "% :  0% (   0 /   38)\n",
      "^ :  0% (   0 /   49)\n",
      "& :  0% (   0 /   31)\n",
      "* :  0% (   0 /   37)\n",
      "[ :  0% (   0 /   43)\n",
      "] :  0% (   0 /   34)\n",
      "{ :  0% (   0 /   40)\n",
      "} :  0% (   0 /   48)\n",
      "< :  0% (   0 /   53)\n",
      "> :  0% (   0 /   44)\n",
      "~ :  0% (   0 /   38)\n",
      "- :  0% (   0 /   43)\n",
      "inv :  0% (   1 / 8667)     1 errors with O\n"
     ]
    }
   ],
   "source": [
    "error_check(en_chset, h_en, Y_en, testimg, testlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate\n",
      "ㅏ :  0% (   2 /  887)     1 errors with ㅐ\n",
      "ㅐ :  0% (   0 /  583)\n",
      "ㅑ :  0% (   0 /  284)\n",
      "ㅒ :  0% (   0 /   44)\n",
      "ㅓ :  0% (   0 /  757)\n",
      "ㅔ :  0% (   0 /  521)\n",
      "ㅕ :  0% (   0 /  515)\n",
      "ㅖ :  2% (   3 /  125)     3 errors with ㅔ\n",
      "ㅗ :  0% (   0 /  680)\n",
      "ㅘ :  0% (   0 /  320)\n",
      "ㅙ :  0% (   0 /  170)\n",
      "ㅚ :  0% (   1 /  395)     1 errors with ㅘ\n",
      "ㅛ :  0% (   0 /  245)\n",
      "ㅜ :  0% (   1 /  650)     1 errors with ㅗ\n",
      "ㅝ :  0% (   0 /  207)\n",
      "ㅞ :  0% (   0 /  140)\n",
      "ㅟ :  0% (   0 /  401)\n",
      "ㅠ :  0% (   0 /  327)\n",
      "ㅡ :  0% (   0 /  602)\n",
      "ㅢ :  0% (   0 /  107)\n",
      "ㅣ :  1% (   4 /  707)     3 errors with ㅏ\n",
      "inv :  0% (   0 / 3333)\n"
     ]
    }
   ],
   "source": [
    "error_check(ko_chset_jung, h_jung, Y_jung, testimg, testlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "tensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
