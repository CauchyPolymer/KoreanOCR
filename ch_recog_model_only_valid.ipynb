{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packs loaded\n",
      "{\n",
      "  \"transport\": \"tcp\",\n",
      "  \"signature_scheme\": \"hmac-sha256\",\n",
      "  \"ip\": \"127.0.0.1\",\n",
      "  \"hb_port\": 35183,\n",
      "  \"control_port\": 45419,\n",
      "  \"kernel_name\": \"\",\n",
      "  \"iopub_port\": 60026,\n",
      "  \"key\": \"83586da5-8735-4068-adc9-bcba2eab867a\",\n",
      "  \"stdin_port\": 56107,\n",
      "  \"shell_port\": 36741\n",
      "}\n",
      "\n",
      "Paste the above JSON into a file, and connect with:\n",
      "    $> jupyter <app> --existing <file>\n",
      "or, if you are local, you can connect with just:\n",
      "    $> jupyter <app> --existing kernel-7e0df336-39b7-40c5-a2c8-d757654e837f.json\n",
      "or even just:\n",
      "    $> jupyter <app> --existing\n",
      "if this is the most recent Jupyter kernel you have started.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import imread\n",
    "import json\n",
    "import gzip\n",
    "import tarfile\n",
    "import random\n",
    "from hangul_utils import check_syllable, split_syllable_char, split_syllables, join_jamos\n",
    "%matplotlib inline\n",
    "plt.rcParams['image.cmap'] = 'Greys'\n",
    "\n",
    "print(\"packs loaded\")\n",
    "%connect_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index loaded\n",
      "tar opened\n",
      " 0% complete (1 / 79200)\n",
      "13% complete (10001 / 79200)\n",
      "25% complete (20001 / 79200)\n",
      "38% complete (30001 / 79200)\n",
      "51% complete (40001 / 79200)\n",
      "63% complete (50001 / 79200)\n",
      "76% complete (60001 / 79200)\n",
      "88% complete (70001 / 79200)\n",
      "image loaded\n",
      "index loaded\n",
      "tar opened\n",
      " 0% complete (1 / 211500)\n",
      " 5% complete (10001 / 211500)\n",
      " 9% complete (20001 / 211500)\n",
      "14% complete (30001 / 211500)\n",
      "19% complete (40001 / 211500)\n",
      "24% complete (50001 / 211500)\n",
      "28% complete (60001 / 211500)\n",
      "33% complete (70001 / 211500)\n",
      "38% complete (80001 / 211500)\n",
      "43% complete (90001 / 211500)\n",
      "47% complete (100001 / 211500)\n",
      "52% complete (110001 / 211500)\n",
      "57% complete (120001 / 211500)\n",
      "61% complete (130001 / 211500)\n",
      "66% complete (140001 / 211500)\n",
      "71% complete (150001 / 211500)\n",
      "76% complete (160001 / 211500)\n",
      "80% complete (170001 / 211500)\n",
      "85% complete (180001 / 211500)\n",
      "90% complete (190001 / 211500)\n",
      "95% complete (200001 / 211500)\n",
      "99% complete (210001 / 211500)\n",
      "image loaded\n",
      "label loaded\n"
     ]
    }
   ],
   "source": [
    "en_chset = []\n",
    "en_chset.extend([\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"])\n",
    "en_chset.extend([\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\",\\\n",
    "              \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\"])\n",
    "en_chset.extend([\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\",\\\n",
    "              \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\"])\n",
    "en_chset.extend([\"(\", \")\", \"'\", \"\\\"\", \".\", \",\", \":\", \";\", \"!\", \"?\", \"/\", \"@\", \"#\", \"$\",\\\n",
    "              \"%\", \"^\", \"&\", \"*\", \"[\", \"]\", \"{\", \"}\", \"<\", \">\", \"~\", \"-\"])\n",
    "\n",
    "ko_chset_cho = [\"ㄱ\", \"ㄲ\", \"ㄴ\", \"ㄷ\", \"ㄸ\", \"ㄹ\", \"ㅁ\", \"ㅂ\", \"ㅃ\", \"ㅅ\", \"ㅆ\", \"ㅇ\", \"ㅈ\", \"ㅉ\", \"ㅊ\", \"ㅋ\", \"ㅌ\", \"ㅍ\", \"ㅎ\"]\n",
    "ko_chset_jung = [\"ㅏ\", \"ㅐ\", \"ㅑ\", \"ㅒ\", \"ㅓ\", \"ㅔ\", \"ㅕ\", \"ㅖ\", \"ㅗ\", \"ㅘ\", \"ㅙ\", \"ㅚ\", \"ㅛ\", \"ㅜ\", \"ㅝ\", \"ㅞ\", \"ㅟ\", \"ㅠ\", \"ㅡ\", \"ㅢ\", \"ㅣ\"]\n",
    "ko_chset_jong = [\"X\", \"ㄱ\", \"ㄲ\", \"ㄳ\", \"ㄴ\", \"ㄵ\", \"ㄶ\", \"ㄷ\", \"ㄹ\", \"ㄺ\", \"ㄻ\", \"ㄼ\", \"ㄽ\", \"ㄾ\", \"ㄿ\", \"ㅀ\", \"ㅁ\", \"ㅂ\", \"ㅄ\", \"ㅅ\", \"ㅆ\", \"ㅇ\", \"ㅈ\", \"ㅊ\", \"ㅋ\", \"ㅌ\", \"ㅍ\", \"ㅎ\"]\n",
    "\n",
    "# Read training and test images from file\n",
    "def get_image_index_from_file(indexf, dataf):\n",
    "    index_data = []\n",
    "    with gzip.open(indexf, 'rt') as arc:\n",
    "        index_data.extend(json.load(arc))\n",
    "        print(\"index loaded\")\n",
    "        arc.close()\n",
    "\n",
    "    # Read-stream mode r|*\n",
    "    with tarfile.open(dataf, \"r|*\") as tar:\n",
    "        print(\"tar opened\")\n",
    "        img_data = []\n",
    "        for i, member in enumerate(index_data):\n",
    "            if i%10000 == 1:\n",
    "                print(\"%2.0f%% complete (%d / %d)\" % (i / len(index_data) * 100, i, len(index_data)))\n",
    "            ti = tar.next()\n",
    "            if ti.name != member['path']:\n",
    "                print(\"ERROR: order doesn't match\")\n",
    "                break;\n",
    "            f = tar.extractfile(ti)\n",
    "            img_data.append(1 - (imread(f)/255))\n",
    "        img = np.array(img_data)\n",
    "        del img_data\n",
    "        print(\"image loaded\")\n",
    "        tar.close()\n",
    "    return (index_data, img)\n",
    "\n",
    "def get_label(index_data):\n",
    "    # len + 1 for one 'invalid' label\n",
    "    label_ko_cho = np.zeros([len(index_data), len(ko_chset_cho)+1])\n",
    "    label_ko_jung = np.zeros([len(index_data), len(ko_chset_jung)+1])\n",
    "    label_ko_jong = np.zeros([len(index_data), len(ko_chset_jong)+1])\n",
    "    label_en = np.zeros([len(index_data), len(en_chset)+1])\n",
    "    for i, member in enumerate(index_data):\n",
    "        target = member['target'] # Target Character\n",
    "        # Is Hangeul?\n",
    "        if (check_syllable(target)):\n",
    "            splited = split_syllable_char(target)\n",
    "            label_en[i][len(en_chset)] = 1\n",
    "            label_ko_cho[i][ko_chset_cho.index(splited[0])] = 1\n",
    "            label_ko_jung[i][ko_chset_jung.index(splited[1])] = 1\n",
    "            if len(splited) < 3:\n",
    "                label_ko_jong[i][0] = 1\n",
    "            else:\n",
    "                label_ko_jong[i][ko_chset_jong.index(splited[2])] = 1\n",
    "        else :\n",
    "            label_ko_cho[i][len(ko_chset_cho)] = 1\n",
    "            label_ko_jung[i][len(ko_chset_jung)] = 1\n",
    "            label_ko_jong[i][len(ko_chset_jong)] = 1\n",
    "            label_en[i][en_chset.index(target)] = 1\n",
    "            \n",
    "    # Concatenate all labels\n",
    "    label = np.concatenate((label_ko_cho, label_ko_jung, label_ko_jong, label_en), axis=1)\n",
    "    print(\"label loaded\")\n",
    "    return label\n",
    "\n",
    "def get_all():\n",
    "    index_data_en, img_en = get_image_index_from_file('data/en/index.json.gz', 'data/en/data.tar.gz')\n",
    "    index_data_ko, img_ko = get_image_index_from_file('data/ko/index.json.gz', 'data/ko/data.tar.gz')\n",
    "    index_data = index_data_en + index_data_ko\n",
    "    img = np.concatenate((img_en, img_ko))\n",
    "    del img_en\n",
    "    del img_ko\n",
    "    label = get_label(index_data)\n",
    "    return (index_data, img, label)\n",
    "        \n",
    "index_data, img, label = get_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffled\n"
     ]
    }
   ],
   "source": [
    "def getIndex(l, indexes):\n",
    "    return [l[i] for i in indexes]\n",
    "\n",
    "def shuffle(n, *lists):\n",
    "    perm = np.random.permutation(n)\n",
    "    lists = list(lists)\n",
    "    for i in range(len(lists)):\n",
    "        if hasattr(lists[i], \"shape\"):\n",
    "            lists[i] = lists[i][perm]\n",
    "        else:\n",
    "            lists[i] = getIndex(lists[i], perm)\n",
    "    return tuple(lists)\n",
    "\n",
    "img, label, index_data = shuffle(img.shape[0], img, label, index_data)\n",
    "\n",
    "print(\"shuffled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainimg = img[:-15000]\n",
    "trainlabel = label[:-15000]\n",
    "testimg = img[-15000:-3000]\n",
    "testlabel = label[-15000:-3000]\n",
    "cvimg = img[-3000:]\n",
    "cvlabel = label[-3000:]\n",
    "randidx = np.random.randint(trainimg.shape[0], size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(290700, 32, 32)\n",
      "{'font': 'Dotum', 'path': '0025059.png', 'target': 'r', 'weight': 'NORMAL'}\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "{'font': 'Dotum', 'path': '0115648.png', 'target': '쌩', 'weight': 'BOLD'}\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFfCAYAAACfj30KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7d1eca9240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFfCAYAAACfj30KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAH3NJREFUeJzt3X2QVPWd7/HPl6fhSWYSiCBRIoqsJlbUGYPiitGLWb1a\nZdbSiK3GUrO5mqhlTalL9OZqfIxC4rAx15vdSpaVaDpqXEvXKMQn3KhREibiQwCfRUEeFB0EhhmG\n+d0/TpP0DMOcb890z6975v2qmirm9Ld/5zv98OH06fM7x0IIAgDEMSh2AwAwkBHCABARIQwAERHC\nABARIQwAERHCABARIQwAERHCABARIQwAEQ2J3YCZjZV0gqR3JG2L2w0AFMVwSftKWhRC+Ki7wpKF\nsJldLOkKSRMkLZN0aQjhj12UniDp7lL1AQARnS3pV90VlCSEzWyWpB9L+l+Slkiql7TIzKaGED7s\nVP6OJN1111066KCD/rqwvr5eDQ0NpWivT1Ra/12dQ6Srv2Hz5s2pY82bN8+1zo0bN7rq8l8Xu/PN\nb35zl2WzZ8/Wrbfe2mHZiBEjXOuMwfscrFy5MnWs+fPnu9bZ2trqqjv11FNTa4466qhdll1xxRX6\n0Y9+1GHZkCHRP4AXpCfv5eXLl+ucc86RcvnWnVI9GvWS/jWEsECSzOwiSSdLukDSnE6126TkjVZb\nW/vXhdXV1R1+rzSV1n9XAVBTU7PL39DU1JQ61rhx41zrbG9vd9VNnDgxtebQQw/dZVl1dfUuy0eN\nGuVaZwze52DQoPSvcj7zmc+41tnS0uKqmzJlSmpNV6/3rt4HlRbCvXwvp+5iLfoXc2Y2VFKdpCd2\nLgvJq+txSdOLvT4AqGSlODpinKTBktZ1Wr5Oyf5hAEBOX34uMEm7PXlxfX29qqur//r7kiVLlM1m\nlclk+qI3AOiRbDarbDbbYZlnt91OpQjhDyXtkDS+0/I9tevW8V81NDR02O9S6QFcyb3vdOaZZ8Zu\noVdOP/302C30WqU/B7NmzYrdQq+lvZczmcwuNY2Njaqrq3ONX/TdESGE7ZKWSpq5c5mZWe7357zj\nVHqIVXr/UuX/DWeccUbsFnqt0p+DSv9PRCr9c1Cq3RG3SbrTzJbqb4eojZT0HyVaHwBUpJKEcAjh\nXjMbJ+l6JbslXpR0QghhQynWBwCVymJf6NPMaiUtXbp0aUUdV9vfeF8HO3bsSK3ZsmWLayzvccKe\n40pHjhzpGmvw4MGuuhi8z4FngkVzc3NR1zl8+PDUmqqqKtdYnuOcK13ePuG6EEJjd7X9/9EAgDJG\nCANARIQwAERECANARIQwAERECANARIQwAERECANARIQwAERUWae4R8kk51hK55lxNmbMmN62MyB5\nn4Nhw4al1nhnpbW1tbnqPL3Fnn1bqdgSBoCICGEAiIgQBoCICGEAiIgQBoCICGEAiIgQBoCICGEA\niIjJGiiId0JBufJOKPBeeun1119PrVm2bJlrrBEjRrjqPJcBW79+vWusu+++21XnuazVCSec4Brr\nxBNPdNVV+mvNiy1hAIiIEAaAiAhhAIiIEAaAiAhhAIiIEAaAiAhhAIiIEAaAiAhhAIiIGXNF4pmJ\n1dzc7Bprzpw5rroXXnghtebAAw90jXX11Ve76saNG5da884777jGuu6661x1H330UWrNySef7Brr\nggsucNV5Z2s98MADqTU33HCDa6yqqipX3Y033phas8cee7jG+tnPfuaqa2lpSa3xXPpK8s+YGyjY\nEgaAiAhhAIiIEAaAiAhhAIiIEAaAiAhhAIiIEAaAiAhhAIio6CFsZteaWXunn78Uez0A0B+Uasbc\nK5JmSto57aitROupKJ7rdEnS888/76pbtGhRas3atWtdY11++eWuOo+NGze66h577DFX3Zo1a1Jr\nxo8f7xrrvPPOc9V5Z3+1tram1nhnSg4Z4ns7Tpw4sWjr9F5zb9Cg9O21mpoa11gD5dpxXqUK4bYQ\nwoYSjQ0A/Uap9gkfYGarzexNM7vLzPYp0XoAoKKVIoSfl3SepBMkXSRpsqT/NrNRJVgXAFS0ou+O\nCCHk76h8xcyWSHpX0hmS5hd7fQBQyUp+KssQQpOZvSZpSnd19fX1qq6u7rAsk8kok8mUsj0A6JVs\nNqtsNtthWVNTk/v+JQ9hMxstaX9JC7qra2hoUG1tbanbAYCi6mpjsbGxUXV1da77l+I44blmdoyZ\nfcHMjpL0gJJD1LIpdwWAAacUW8J7S/qVpLGSNkh6RtKRIYT0yyMAwABTii/m2IkLAE5cY64Ptbe3\nu+o+/PDDoq1z//33d9XtueeeRVun53pkkrR9+/airfPwww931XlmfpU7Zpz1L5X/igSACkYIA0BE\nhDAAREQIA0BEhDAAREQIA0BEhDAAREQIA0BETNboQ21tvqs8rVu3zlXnOWh/5MiRrrGGDh3qqvP4\n+OOPXXVbt24t2joPOOAAV533skXeiTVAb7ElDAAREcIAEBEhDAAREcIAEBEhDAAREcIAEBEhDAAR\nEcIAEBEhDAARMWOuD3kvW7RlyxZXXQghtcZ7CSHPWF5r1qxx1TU3N7vqPDMDR48e7RrLe3kjZsyh\nr7AlDAAREcIAEBEhDAAREcIAEBEhDAAREcIAEBEhDAAREcIAEBEhDAARMWOuD73yyiuuupaWlqKt\n03u9us2bN7vqhg0bllrzxhtvuMbyzkrzzHLzzKoDyhFbwgAQESEMABERwgAQESEMABERwgAQESEM\nABERwgAQESEMABEVPFnDzGZIulJSnaS9JP1jCOGhTjXXS/onSTWSnpX0nRCC7wj+MuO97M+OHTtS\na5544gnXWNu2bXPVebz66quuumXLlrnqDj744NSaF1980TWWl2dSR1NTk2usYl7Gqdi8vbW2thal\nBuWhJ1vCoyS9KOliSbu8asxstqRLJF0oaZqkLZIWmVn6VCsAGGAK3hIOISyUtFCSrOu5opdJuiGE\n8F+5mnMlrZP0j5Lu7XmrAND/FHWfsJlNljRB0l8/d4cQNkl6QdL0Yq4LAPqDYn8xN0HJLorOZ41Z\nl7sNAJCnr86iZupi/3G++vp6VVdXd1iWyWSUyWRK2RcA9Eo2m1U2m+2wzPtFsVT8EF6rJHDHq+PW\n8J6S/tzdHRsaGlRbW1vkdgCgtLraWGxsbFRdXZ3r/kXdHRFCeFtJEM/cuczMxkg6QtJzxVwXAPQH\nPTlOeJSkKUq2eCVpPzM7RNLGEMJ7kuZJ+r6ZvSHpHUk3SHpf0oNF6RgA+pGe7I44XNJTSvbxBkk/\nzi2/U9IFIYQ5ZjZS0r8qmazxe0n/M4TA0eMA0ElPjhN+Wim7MUIIP5D0g5611De8s5O8dZ5L+jz1\n1FOusbyX/fHYsGGDq+6aa65x1Z177rmpNc8++6xrrGL6/e9/76o75phjXHWeSyoV29atW111V155\nZWqNZwan5L+U1uDBg111KBznjgCAiAhhAIiIEAaAiAhhAIiIEAaAiAhhAIiIEAaAiAhhAIiIEAaA\niPrqVJYVa8uWLa66uXPnpta89tprrrGGDh3qqhs5cmRqzaZNm1xjLV68uKh1fe3ee30XbTnnnHNc\ndZMnT+5NOz3inSm5atWqEneyK2bMlQ5bwgAQESEMABERwgAQESEMABERwgAQESEMABERwgAQESEM\nABFV1GSNYl6SaPPmza6x5syZ46rLZrOpNd7+Z86cmV4k6cILL0ytufnmm11j/fGPf3TVFZN3AoDn\nUj2ey0tJ0uWXX+6qu/7661113sk8Ht7H40tf+lJqjffyRsuXL3fVoXTYEgaAiAhhAIiIEAaAiAhh\nAIiIEAaAiAhhAIiIEAaAiAhhAIiIEAaAiMpmxlwIIXVGmXfG2bp161JrrrrqKtdY3svmNDc3p9bs\ns88+rrG+973vueqmT5+eWvPxxx+7xooxY+4b3/iGq27JkiWpNW+99ZZrrEceecRV9/LLL7vqhgwp\n3lvIc7kqyffa3bp1q2usSy65xFXX1tbmqkPh2BIGgIgIYQCIiBAGgIgIYQCIiBAGgIgIYQCIiBAG\ngIgIYQCIqOAQNrMZZvaQma02s3YzO6XT7fNzy/N/fEfIA8AA05PpPqMkvSjp3yXdv5uaRyWdJ8ly\nv7f0YD095rlWl/caXN5ZetXV1ak11113nWusadOmueqWLVuWWrNgwQLXWF5mllpzxBFHuMa66aab\nXHXvv/9+as1ll13mGuull15y1a1evdpVN3ToUFddMQ0fPjy1pr29vQ86QTEUHMIhhIWSFkqS7f4d\n2RJC2NCbxgBgICjVPuFjzWydma0wszvM7LMlWg8AVLRSnMDnUSW7Kd6WtL+kH0p6xMymB+9newAY\nIIoewiGE/NOOvWpmL0t6U9Kxkp4q9voAoJKV/FSWIYS3zexDSVPUTQjX19erpqamw7IzzzxTmUym\nxB0CQM9ls1lls9kOy5qamtz3L3kIm9neksZK+qC7uoaGBtXW1pa6HQAoqkwms8vGYmNjo+rq6lz3\nLziEzWyUkq3anUdG7Gdmh0jamPu5Vsk+4bW5ulslvSZpUaHrAoD+ridbwocr2a0Qcj8/zi2/U9J3\nJX1Z0rmSaiStURK+14QQtve6WwDoZ3pynPDT6v7QthN70oiZuSYCeIwbNy61Zt68ea6xvJckmjBh\nQmrNrFmzXGO1tra66jwTMZ577jnXWF777rtvas3cuXNdY02aNKlodXfeeadrrFtuucVVN3r0aFdd\nS0v6PKRiT5hB/8K5IwAgIkIYACIihAEgIkIYACIihAEgIkIYACIihAEgIkIYACIihAEgopKfwKeY\nijWjTpI++1nfeeavueaaoq2zqqrKVTdixAhX3dVXX92bdjp4+OGHXXW33357as2RRx7Z23YKduCB\nB7rqPP1L/stfecbzvm69l0ryXL4LlYMtYQCIiBAGgIgIYQCIiBAGgIgIYQCIiBAGgIgIYQCIiBAG\ngIgIYQCIqKJmzHkVc2add5abh7evEIKrbvz48ak1N954o2usSy+91FXnmc330ksvucby1r355pup\nNR999JFrrObmZled9zlYsmRJak1NTY1rrK985SuuukGD0red3n//fddY3ll6Q4akR4V3LHTEljAA\nREQIA0BEhDAAREQIA0BEhDAAREQIA0BEhDAAREQIA0BE/XKyRjEVc+JHDN7L9Dz66KOuumw2m1qz\ndOlS11htbW2uuoFi0aJFrrrnn38+tWbkyJGusaZNm+aqO/vss1NrjjrqKNdY6IgtYQCIiBAGgIgI\nYQCIiBAGgIgIYQCIiBAGgIgIYQCIiBAGgIgIYQCIqKAZc2Z2laRTJR0oqVnSc5JmhxBey6upknSb\npFmSqiQtkvTdEML6YjVdqbyXzPHWvfvuu6k1V1xxhWushx9+2FXX2tqaWjNs2DDXWBMmTHDV7bHH\nHqk1nssuSb5LAxVi+/btqTVbt251jdXU1OSq++STT1JrNm3a5BqrpaXFVTdjxozUmtNOO801Fjoq\n9BU5Q9Ltko6QdLykoZJ+Z2b574B5kk6WdJqkYyRNlHR/71sFgP6noC3hEMJJ+b+b2XmS1kuqk/SM\nmY2RdIGkM0MIT+dqzpe03MymhRDSr4oIAANIbz+b1UgKkjbmfq9TEuxP7CwIIayUtErS9F6uCwD6\nnR6HsCWnF5sn6ZkQwl9yiydIag0hdN4htS53GwAgT29OZXmHpC9KOtpRa0q2mHervr5e1dXVHZZl\nMhllMpkeNwgApZbNZnc5xav3S1aphyFsZj+VdJKkGSGENXk3rZU0zMzGdNoa3lPJ1vBuNTQ0qLa2\ntiftAEA0XW0sNjY2qq6uznX/gndH5AL465KOCyGs6nTzUkltkmbm1U+VNEnSHwpdFwD0d4UeJ3yH\npIykUyRtMbPxuZuaQgjbQgibzOwXkm4zs48lfSrpJ5Ke5cgIANhVobsjLlKyb3dxp+XnS1qQ+3e9\npB2SfqNkssZCSRf3vEUA6L8KPU44dfdFCKFF0qW5H/SAd4bVjTfemFrz4IMPusbyXovOcx2xs846\nq2hjSdLEiRNTa7zXVBsyxPeS985a9MyY835J8/bbb7vqfvvb36bW/PKXv3SNtXbtWlfd3LlzU2v2\n3Xdf11jnnnuuq26g4NwRABARIQwAERHCABARIQwAERHCABARIQwAERHCABARIQwAERHCABBRb05l\niRLxXDtOkhYuXJha450J5z3j0/z581Nr9t9/f9dYxb7eWwyea9uNGTPGNdY+++zjqjviiCNSa448\n8kjXWOeff76r7tNPP02teeCBB1xjnX766a467yzISlf57wIAqGCEMABERAgDQESEMABERAgDQESE\nMABERAgDQESEMABExGSNMrRx40ZX3fr164u2zpkzZ6YXSZo0aVJqjXcShpm56tBRVVVVas2xxx7r\nGstz6ShJWrFiRWrNBx984Bpry5YtrjomawAASo4QBoCICGEAiIgQBoCICGEAiIgQBoCICGEAiIgQ\nBoCICGEAiIgZc2Vo+PDhrjrPzKm2tjbXWN5LKrW0tKTWePrCrkIIrrr29vbUGu9syk8++cRV5+Gd\n4TZs2LCirbM/YEsYACIihAEgIkIYACIihAEgIkIYACIihAEgIkIYACIihAEgooJC2MyuMrMlZrbJ\nzNaZ2QNmNrVTzWIza8/72WFmdxS3bQDoHwqdMTdD0u2S/pS77w8l/c7MDgohNOdqgqR/k/R/JO28\niNjWIvQ6YHzhC19w1U2bNi21ZvHixa6xHnroIVfd5MmTU2u+9a1vucb63Oc+56rzzCAcOnSoayzv\nde2KOXuttbXVNdbmzZtdda+//npqzS233OIaa8OGDa66IUPSo2L69OmusUaNGuWqGygKCuEQwkn5\nv5vZeZLWS6qT9EzeTVtDCL5nFwAGsN7uE65RsuXb+fLAZ5vZBjN72cxuNrMRvVwPAPRLPT6BjyWf\n6+ZJeiaE8Je8m+6W9K6kNZK+LGmOpKmSTu9FnwDQL/XmLGp3SPqipL/PXxhC+Hner6+a2VpJj5vZ\n5BDC27sbrL6+XtXV1R2WZTIZZTKZXrQIAKWVzWaVzWY7LGtqanLfv0chbGY/lXSSpBkhhA9Syl9Q\n8gXdFEm7DeGGhgbV1tb2pB0AiKarjcXGxkbV1dW57l9wCOcC+OuSvhpCWOW4y2FK9hunhTUADDgF\nhXDueN+MpFMkbTGz8bmbmkII28xsP0lnSXpE0keSDpF0m6SnQwivFK9tAOgfCt0SvkjJVu3iTsvP\nl7RAUquk4yVdJmmUpPck3Sfppl51CQD9VKHHCXd7SFsI4X1Jx/amIUhjx4511V1xxRWpNcuXL3eN\ntXbtWlfdrbfemlqzYMEC11jeg/v33nvv1JqamhrXWN5JHd7JGtu2bUut8U6IWLFihavuT3/6U2rN\n1q2++VHeySvHH398as2FF17oGmvw4MGuuoGCc0cAQESEMABERAgDQESEMABERAgDQESEMABERAgD\nQESEMABERAgDQES9OZUlCuSdnTRokO//xpkzZ6bW3HPPPa6xbr75ZlfdCy+8kFqzZs0a11j333+/\nqw4deWacTZo0yTXWKaec4qq78sorU2s+//nPu8byvg8GCraEASAiQhgAIiKEASAiQhgAIiKEASAi\nQhgAIiKEASAiQhgAIiKEASAiZsyVIe+MomHDhqXWzJgxwzXWfffd56pbsmRJas2TTz7pGmvlypWu\nujfffDO1ZuPGja6xPNeEk/yzFkeMGJFas9dee7nGmjJliqvu0EMPTa352te+5hpr6tSprjrvtflQ\nOLaEASAiQhgAIiKEASAiQhgAIiKEASAiQhgAIiKEASAiQhgAImKyRgUr5mViRo8e7ao77rjjUmuO\nPvpo11jeiROeuu3bt7vGam9vd9V5eS41VFVV5Rpr+PDhRavz9FUILklUOmwJA0BEhDAAREQIA0BE\nhDAAREQIA0BEhDAAREQIA0BEhDAAREQIA0BEBc2YM7OLJH1H0r65Ra9Kuj6EsDB3e5Wk2yTNklQl\naZGk74YQ1herYRQmhOCq884kW716dWpNS0uLa6yBwnMJJEkaOXKkq84ze40ZbpWj0C3h9yTNllSX\n+3lS0oNmdlDu9nmSTpZ0mqRjJE2UdH9xWgWA/qegLeEQwm87Lfq+mX1H0pFmtlrSBZLODCE8LUlm\ndr6k5WY2LYSQfoVIABhgerxP2MwGmdmZkkZK+oOSLeMhkp7YWRNCWClplaTpvewTAPqlgs+iZmYH\nKwnd4ZI+lXRqCGGFmR0mqTWEsKnTXdZJmtDrTgGgH+rJqSxXSDpEUo2Sfb8LzOyYbupNUuq3Q/X1\n9aquru6wLJPJKJPJ9KBFAOgb2WxW2Wy2w7Kmpib3/c377fluBzB7TNIbku6V9Likz+RvDZvZO5Ia\nQgj/spv710paunTpUtXW1vaqF+yKoyPiGzt2rKuupqbGVcfREeWvsbFRdXV1klQXQmjsrrYYxwkP\nUnI42lJJbZJm7rzBzKZKmqRk9wUAoJNCjxO+SdKjSg5V20PS2ZK+KukfQgibzOwXkm4zs4+V7C/+\niaRnOTICALpW6D7h8ZIWSNpLUpOkl5QE8JO52+sl7ZD0GyVbxwslXVycVgGg/yn0OOF/Srm9RdKl\nuR9UkNbWVlfd7NmzU2uWLVvW23Yqhmff68UX+7ZDvv3tb7vqhg4d6qpDZeDcEQAQESEMABGVbQh3\nPu6u0lR6/5J07733xm6hVwo5VrNc/frXv47dQq/0h/dBqf8GQrhEKr1/qfJDeNOmzpM3K88999wT\nu4Ve6Q/vgwEbwgAwEBDCABARIQwAEfXkBD7FNlySli9f3mFhU1OTGhu7nXJd1sqlf++5I7o630NT\nU5P+/Oc/d1i2cePG1LGam5t9zZXYjh07St6L5zjhVatWucbq/FhLyX7tzsuHDCmHt61PubwPeqMn\nf0Neng1Pq+31CXx6y8zOknR31CYAoDTODiH8qruCcgjhsZJOkPSOpG1RmwGA4hiu5Fqci0IIH3VX\nGD2EAWAg44s5AIiIEAaAiAhhAIiIEAaAiAhhAIioLEPYzC42s7fNrNnMnjezr8TuycPMrjWz9k4/\nf4ndV3fMbIaZPWRmq3P9ntJFzfVmtsbMtprZY2Y2JUavXUnr38zmd/GcPBKr387M7CozW2Jmm8xs\nnZk9kLs2Y35NlZn9XzP70Mw+NbPfmNmesXrO5+x/cafHf4eZ3RGr587M7CIzW2ZmTbmf58zsxLzb\nS/r4l10Im9ksST+WdK2kwyQtk7TIzMZFbczvFSWXgZqQ+zk6bjupRkl6UcllqHY5XtHMZku6RNKF\nkqZJ2qLk+RjWl012o9v+cx5Vx+ck0zetucyQdLukIyQdL2mopN+Z2Yi8mnmSTpZ0mqRjJE2UdH8f\n97k7nv6DpH/T356DvST9cx/32Z33JM2WVJf7eVLSg2Z2UO720j7+IYSy+pH0vKR/yfvdJL0v6Z9j\n9+bo/VpJjbH76EX/7ZJO6bRsjaT6vN/HSGqWdEbsfp39z5f0n7F7K+BvGJf7O47Oe7xbJJ2aV/N3\nuZppsftN6z+37ClJt8XurcC/4yNJ5/fF419WW8JmNlTJ/0RP7FwWkr/6cUnTY/VVoANyH43fNLO7\nzGyf2A31lJlNVrLlkv98bJL0girn+ZCkY3MflVeY2R1m9tnYDXWjRsmW486TdNQpOcdL/nOwUtIq\nledz0Ln/nc42sw1m9rKZ3dxpS7lsmNkgMztT0khJf1AfPP7ldiaQcZIGS1rXafk6Jf/7lLvnJZ0n\naaWSj1w/kPTfZnZwCGFLxL56aoKSN1RXz8eEvm+nRx5V8tHxbUn7S/qhpEfMbHruP/iyYcnZgOZJ\neiaEsPO7hAmSWnP/+eUru+dgN/1Lyblh3lXyqerLkuZImirp9D5vcjfM7GAloTtc0qdKtnxXmNlh\nKvHjX24hvDum3e/vKxshhEV5v75iZkuUvPjOUPKxuL+oiOdDkkII+ZcHedXMXpb0pqRjlXxMLid3\nSPqifN8jlONzsLP/v89fGEL4ed6vr5rZWkmPm9nkEMLbfdlgN1ZIOkTJlvxpkhaY2THd1Bft8S+r\n3RGSPpS0Q8kO/Hx7atetsbIXQmiS9JqksjmaoEBrlbzY+sXzIUm5N/2HKrPnxMx+KukkSceGENbk\n3bRW0jAzG9PpLmX1HHTq/4OU8heUvK7K5jkIIbSFEN4KITSGEP63kgMCLlMfPP5lFcIhhO2Slkqa\nuXNZ7iPOTEnPxeqrp8xstJKPwGkvyrKUC6y16vh8jFHyTXjFPR+SZGZ7SxqrMnpOcgH2dUnHhRA6\nn3x4qaQ2dXwOpkqapOTjc3Qp/XflMCVbkWXzHHRhkKQq9cHjX467I26TdKeZLZW0RFK9kp3k/xGz\nKQ8zmyvpv5Tsgvi8pOuUPIFle7VDMxulZItk59nJ9zOzQyRtDCG8p2Qf3/fN7A0lpxu9QcnRKg9G\naHcX3fWf+7lWyT7htbm6W5V8Olm062h9L3e8bEbSKZK2mNnOTx1NIYRtIYRNZvYLSbeZ2cdK9lf+\nRNKzIYQlcbr+m7T+zWw/SWdJekTJEQeHKHmPPx1CeCVGz52Z2U1Kvjt4T9Ieks6W9FVJ/9Anj3/s\nQ0F2c3jId5W84ZuV/G9zeOyenH1nlQRUs5JvT38laXLsvlJ6/qqSw212dPr597yaHyj5UmWrkvCa\nErtvT/9KvmRZqCSAt0l6S9L/k/S52H3n9d9V7zsknZtXU6XkWNwPcyFwn6Q9Y/fu6V/S3pIWS9qQ\ne/2sVPLl6OjYvef9DT/PvTaac6+V30n6H331+HM+YQCIqKz2CQPAQEMIA0BEhDAAREQIA0BEhDAA\nREQIA0BEhDAAREQIA0BEhDAAREQIA0BEhDAARPT/AaAxByvkN+0nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7d1ef1ef98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(img.shape)\n",
    "plt.figure()\n",
    "plt.imshow(img[0], interpolation='none')\n",
    "print(index_data[0])\n",
    "print(label[0])\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(img[1], interpolation='none')\n",
    "print(index_data[1])\n",
    "print(label[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function loaded\n"
     ]
    }
   ],
   "source": [
    "def get_batch(i, batch_size, input_var):\n",
    "    if batch_size > input_var.shape[0]:\n",
    "        return input_var\n",
    "    start = (i*batch_size)%input_var.shape[0]\n",
    "    overflow = start + batch_size - input_var.shape[0]\n",
    "    if overflow <= 0:\n",
    "        return input_var[start:start+batch_size]\n",
    "    else:\n",
    "        return np.r_[input_var[start:], input_var[:overflow]]\n",
    "    \n",
    "def flatten_cnn(layer):\n",
    "    layer_shape = layer.get_shape().as_list()\n",
    "    n_out = layer_shape[1] * layer_shape[2] * layer_shape[3]\n",
    "    return tf.reshape(layer, [-1, n_out])\n",
    "\n",
    "def build_nn(shape, X, name):\n",
    "    n_before = int(X.get_shape()[1])\n",
    "    W = tf.Variable(tf.truncated_normal([n_before, shape], stddev=0.1), name=name+\"_W\")\n",
    "    b = tf.Variable(tf.constant(0.1, shape=[shape]), name=name+\"_b\")\n",
    "    return tf.matmul(X, W)+b\n",
    "\n",
    "def build_cnn(cnn_shape, patch_shape, X, name, stride=1):\n",
    "    n_before = int(X.get_shape()[3])\n",
    "    W = tf.Variable(tf.truncated_normal([patch_shape[0], patch_shape[1], n_before, cnn_shape], stddev=0.1),\n",
    "                   name=name+\"_W\")\n",
    "    b = tf.Variable(tf.constant(0.1, shape=[cnn_shape]), name=name+\"_b\")\n",
    "    layer = tf.nn.relu(tf.nn.conv2d(X, W, strides=[1, stride, stride, 1], padding='SAME') + b)\n",
    "    return layer\n",
    "\n",
    "def max2d_pool(layer):\n",
    "    return tf.nn.max_pool(layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def slice_label(tf_label, len_tuple):\n",
    "    cur = 0\n",
    "    sliced = []\n",
    "    for l in len_tuple:\n",
    "        sliced.append(tf.slice(tf_label, [0, cur], [-1, l]))\n",
    "        cur += l\n",
    "    return tuple(sliced)\n",
    "\n",
    "print(\"function loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn_1_5_W:0\n",
      "cnn_1_5_b:0\n",
      "cnn_1_3_W:0\n",
      "cnn_1_3_b:0\n",
      "cnn_2_5_W:0\n",
      "cnn_2_5_b:0\n",
      "cnn_2_3_W:0\n",
      "cnn_2_3_b:0\n",
      "cnn_2_1_W:0\n",
      "cnn_2_1_b:0\n",
      "cnn_3_5_reduce_W:0\n",
      "cnn_3_5_reduce_b:0\n",
      "cnn_3_5_W:0\n",
      "cnn_3_5_b:0\n",
      "cnn_3_3_reduce_W:0\n",
      "cnn_3_3_reduce_b:0\n",
      "cnn_3_3_W:0\n",
      "cnn_3_3_b:0\n",
      "cnn_3_1_W:0\n",
      "cnn_3_1_b:0\n",
      "dense_1_W:0\n",
      "dense_1_b:0\n",
      "logit_W:0\n",
      "logit_b:0\n",
      "session loaded\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, [None, 32, 32])\n",
    "Y = tf.placeholder(tf.float32, [None, 160])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "Y_cho, Y_jung, Y_jong, Y_en = slice_label(Y,\n",
    "                                         (len(ko_chset_cho)+1,\n",
    "                                         len(ko_chset_jung)+1,\n",
    "                                         len(ko_chset_jong)+1,\n",
    "                                         len(en_chset)+1))\n",
    "# Small inception model\n",
    "# http://laonple.blog.me/220704822964\n",
    "X_reshape = tf.reshape(X, [-1, 32, 32, 1])\n",
    "cnn_1_5 = build_cnn(12, [5,5], X_reshape, \"cnn_1_5\")\n",
    "cnn_1_3 = build_cnn(36, [3,3], X_reshape, \"cnn_1_3\")\n",
    "cnn_1_concat = tf.concat(3, [cnn_1_5, cnn_1_3])\n",
    "cnn_1_pool = max2d_pool(cnn_1_concat) # 16 * 16 * 48\n",
    "\n",
    "cnn_2_5 = build_cnn(18, [5,5], cnn_1_pool, \"cnn_2_5\")\n",
    "cnn_2_3 = build_cnn(48, [3,3], cnn_1_pool, \"cnn_2_3\")\n",
    "cnn_2_1 = build_cnn(30, [1,1], cnn_1_pool, \"cnn_2_1\")\n",
    "cnn_2_concat = tf.concat(3, [cnn_2_5, cnn_2_3, cnn_2_1])\n",
    "cnn_2_pool = max2d_pool(cnn_2_concat) # 8 * 8 * 96\n",
    "\n",
    "cnn_3_5_reduce = build_cnn(18, [1,1], cnn_2_pool, \"cnn_3_5_reduce\")\n",
    "cnn_3_5 = build_cnn(36, [5,5], cnn_3_5_reduce, \"cnn_3_5\")\n",
    "cnn_3_3_reduce = build_cnn(64, [1,1], cnn_2_pool, \"cnn_3_3_reduce\")\n",
    "cnn_3_3 = build_cnn(96, [3,3], cnn_3_3_reduce, \"cnn_3_3\")\n",
    "cnn_3_1 = build_cnn(60, [1,1], cnn_2_pool, \"cnn_3_1\")\n",
    "cnn_3_concat = tf.concat(3, [cnn_3_5, cnn_3_3, cnn_3_1])\n",
    "cnn_3_pool = max2d_pool(cnn_3_concat) # 4 * 4 * 192\n",
    "\n",
    "dense_1 = tf.nn.relu(build_nn(1024, flatten_cnn(cnn_3_pool), \"dense_1\"))\n",
    "dropout_1 = tf.nn.dropout(dense_1, keep_prob)\n",
    "\n",
    "logit = build_nn(160, dropout_1, \"logit\")\n",
    "logit_cho, logit_jung, logit_jong, logit_en = slice_label(logit,\n",
    "                                         (len(ko_chset_cho)+1,\n",
    "                                         len(ko_chset_jung)+1,\n",
    "                                         len(ko_chset_jong)+1,\n",
    "                                         len(en_chset)+1))\n",
    "h_cho = tf.nn.softmax(logit_cho)\n",
    "h_jung = tf.nn.softmax(logit_jung)\n",
    "h_jong = tf.nn.softmax(logit_jong)\n",
    "h_en = tf.nn.softmax(logit_en)\n",
    "\n",
    "learning_rate = tf.placeholder(tf.float32)\n",
    "cost_cho = tf.nn.softmax_cross_entropy_with_logits(logit_cho, Y_cho)\n",
    "cost_jung = tf.nn.softmax_cross_entropy_with_logits(logit_jung, Y_jung)\n",
    "cost_jong = tf.nn.softmax_cross_entropy_with_logits(logit_jong, Y_jong)\n",
    "cost_en = tf.nn.softmax_cross_entropy_with_logits(logit_en, Y_en)\n",
    "cost = cost_cho + cost_jung * 1.5 + cost_jong * 0.5 + cost_en\n",
    "cost_mean = tf.reduce_mean(cost) # mean of batch set\n",
    "\n",
    "var_before_adam = tf.all_variables()\n",
    "\n",
    "train = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "correct_cho = tf.equal(tf.argmax(Y_cho,1), tf.argmax(h_cho,1))\n",
    "correct_jung = tf.equal(tf.argmax(Y_jung,1), tf.argmax(h_jung,1))\n",
    "correct_jong = tf.equal(tf.argmax(Y_jong,1), tf.argmax(h_jong,1))\n",
    "correct_two = tf.logical_or(tf.logical_and(correct_cho, tf.logical_or(correct_jung, correct_jong)),\n",
    "                           tf.logical_and(correct_jung, correct_jong))\n",
    "correct_ko = tf.logical_and(tf.logical_and(correct_cho, correct_jung), correct_jong)\n",
    "correct_en = tf.equal(tf.argmax(Y_en,1), tf.argmax(h_en,1))\n",
    "correct_all = tf.logical_and(correct_ko, correct_en)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_all, tf.float32))\n",
    "accuracy_two = tf.reduce_mean(tf.cast(correct_two, tf.float32))\n",
    "accuracy_cho = tf.reduce_mean(tf.cast(correct_cho, tf.float32))\n",
    "accuracy_jung = tf.reduce_mean(tf.cast(correct_jung, tf.float32))\n",
    "accuracy_jong = tf.reduce_mean(tf.cast(correct_jong, tf.float32))\n",
    "accuracy_ko = tf.reduce_mean(tf.cast(correct_ko, tf.float32))\n",
    "accuracy_en = tf.reduce_mean(tf.cast(correct_en, tf.float32))\n",
    "\n",
    "sess = tf.Session()\n",
    "for v in var_before_adam:\n",
    "    print (v.name)\n",
    "print(\"session loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf function loaded\n"
     ]
    }
   ],
   "source": [
    "def init_session():\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    print(\"session initialized\")\n",
    "    \n",
    "def fetch_in_batch(fetch_tuple, imgset, labelset, i, batchsize):\n",
    "    batch_x = get_batch(i, batchsize, imgset)\n",
    "    batch_y = get_batch(i, batchsize, labelset)\n",
    "    return sess.run(fetch_tuple, feed_dict={X:batch_x, Y:batch_y, keep_prob:1})\n",
    "    \n",
    "def batch_accuracy(imgset, labelset):\n",
    "    allsize = imgset.shape[0]\n",
    "    batchsize = 100\n",
    "    batch_per_epoch = int(allsize/batchsize)\n",
    "    batch_accuracy = 0\n",
    "    for i in range(batch_per_epoch):\n",
    "        batch_accuracy += fetch_in_batch(accuracy, imgset, labelset, i, batchsize)\n",
    "    return batch_accuracy / batch_per_epoch\n",
    "\n",
    "def get_accuracy_no_batch(imgset, labelset):\n",
    "    return sess.run((accuracy, accuracy_cho, accuracy_jung, accuracy_jong, accuracy_two, accuracy_en),\n",
    "                                        feed_dict={X:imgset, Y:labelset, keep_prob:1})\n",
    "\n",
    "def get_accuracy(imgset, labelset, batch=True):\n",
    "    if batch:\n",
    "        allsize = imgset.shape[0]\n",
    "        batchsize = 100\n",
    "        batch_per_epoch = int(allsize/batchsize)\n",
    "        temp_tuple = 0, 0, 0, 0, 0, 0\n",
    "        for i in range(batch_per_epoch):\n",
    "            batch_x = get_batch(i, batchsize, imgset)\n",
    "            batch_y = get_batch(i, batchsize, labelset)\n",
    "            temp_tuple = tuple([item1 + item2 for item1, item2 in\n",
    "                                zip(temp_tuple,\n",
    "                                    get_accuracy_no_batch(batch_x, batch_y))])\n",
    "        tacc, tacc_cho, tacc_jung, tacc_jong, tacc_two, tacc_en = tuple([item / batch_per_epoch for item in temp_tuple])\n",
    "    else:\n",
    "        tacc, tacc_cho, tacc_jung, tacc_jong, tacc_two, tacc_en = get_accuracy_no_batch(imgset, labelset)\n",
    "    return tacc, tacc_cho, tacc_jung, tacc_jong, tacc_two, tacc_en\n",
    "    \n",
    "def print_accuracy(imgset, labelset, batch=True):\n",
    "    tacc, tacc_cho, tacc_jung, tacc_jong, tacc_two, tacc_en = get_accuracy(imgset, labelset, batch)\n",
    "    print (\"overall accuracy = %.3f                          \" % tacc)\n",
    "    print (\"two of three = %.3f\" % tacc_two)\n",
    "    print (\"cho = %.3f\" % tacc_cho)\n",
    "    print (\"jung = %.3f\" % tacc_jung)\n",
    "    print (\"jong = %.3f\" % tacc_jong)\n",
    "    print (\"en = %.3f\" % tacc_en)\n",
    "\n",
    "def do_training(is_console=False, lr_init = 0.003):\n",
    "    trainsize = trainimg.shape[0]\n",
    "    batchsize = 100\n",
    "    batch_per_epoch = int(trainsize/batchsize)\n",
    "    print (\"Training %d, mini-batch %d * %d\" % (trainsize, batchsize, batch_per_epoch))\n",
    "\n",
    "    lr = lr_init\n",
    "    for i in range(batch_per_epoch*5):\n",
    "        if i % 200 == 0 :\n",
    "            tacc = get_accuracy(cvimg, cvlabel, True)[0]\n",
    "            print (\"%6dth epoch : cv accuracy = %.3f                  \" % (i // batch_per_epoch, tacc))\n",
    "            \n",
    "        if i % batch_per_epoch == 0 :\n",
    "            print_accuracy(testimg, testlabel, True)\n",
    "\n",
    "        batch_x = get_batch(i, batchsize, trainimg)\n",
    "        batch_y = get_batch(i, batchsize, trainlabel)\n",
    "        cur_cost = sess.run((train, cost_mean), feed_dict={X:batch_x, Y:batch_y, keep_prob:0.5, learning_rate:lr})[1]\n",
    "        if(is_console):\n",
    "            print (\"%dth... lr = %.2e, cost = %.2e\\r\" % (i, lr, cur_cost), end=\"\")\n",
    "        lr = lr * (1 - 0.0003)\n",
    "    print(\"train complete--------------------------------\")\n",
    "    print(\"test accuracy ---\")\n",
    "    print_accuracy(testimg, testlabel, True)\n",
    "    print(\"train accuracy ---\")\n",
    "    print_accuracy(trainimg, trainlabel, True)\n",
    "    \n",
    "def error_check(chset, pred_tf, label_tf, imgset, labelset):\n",
    "    label_len = label_tf.get_shape()[1]\n",
    "    n_error = np.zeros([label_len, label_len])\n",
    "    n_all = np.zeros(label_len)\n",
    "    new_chset = chset + [\"inv\"]\n",
    "    \n",
    "    allsize = imgset.shape[0]\n",
    "    batchsize = 100\n",
    "    batch_per_epoch = int(allsize/batchsize)\n",
    "    for i in range(batch_per_epoch):\n",
    "        h, y = fetch_in_batch((pred_tf, label_tf), imgset, labelset, i, batchsize)\n",
    "        for j in range(batchsize):\n",
    "            n_all[np.argmax(y[j])] += 1\n",
    "            if (np.argmax(h[j]) != np.argmax(y[j])):\n",
    "                n_error[np.argmax(y[j])][np.argmax(h[j])] += 1\n",
    "\n",
    "    print (\"Error rate\")\n",
    "    for i, ch in enumerate(new_chset):\n",
    "        most_error = np.argmax(n_error[i])\n",
    "        print (\"%s : %2.0f%% (%4d / %4d)\" %\n",
    "               (ch, float(np.sum(n_error[i])) / n_all[i] * 100, np.sum(n_error[i]), n_all[i]), end=\"\")\n",
    "        if n_error[i][most_error] > 0:\n",
    "            print (\"%6d errors with %s\" % (n_error[i][most_error], new_chset[most_error]))\n",
    "        else:\n",
    "            print (\"\")\n",
    "            \n",
    "def save_ckpt(path):\n",
    "    saver = tf.train.Saver(var_before_adam)\n",
    "    saver.save(sess, path)\n",
    "    print(\"ckpt saved\")\n",
    "    \n",
    "def load_ckpt(path):\n",
    "    saver = tf.train.Saver(var_before_adam)\n",
    "    saver.restore(sess, path)\n",
    "    print(\"ckpt loaded\")\n",
    "            \n",
    "print(\"tf function loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall accuracy = 0.000                          \n",
      "two of three = 0.161\n",
      "cho = 0.176\n",
      "jung = 0.057\n",
      "jong = 0.261\n",
      "en = 0.003\n"
     ]
    }
   ],
   "source": [
    "print_accuracy(testimg, testlabel, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "error_check(en_chset, h_en, Y_en, testimg, testlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error_check(ko_chset_jung, h_jung, Y_jung, testimg, testlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "tensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
